" Effects spin orbit coupling superconducting proximity devices application CoSiTiSi heterostructures Vivek Mishra Fu-Chun Zhang and Stefan Kirchner Kavli Institute for Theoretical Sciences University Chinese Academy Sciences Beijing China CAS Center for Excellence Topological Quantum Computation University Chinese Academy Sciences Beijing China Zhejiang Institute Modern Physics Department Physics Zhejiang University Hangzhou China Zhejiang Province Key Laboratory Quantum Technology and Device Zhejiang University Hangzhou China Dated January Motivated the recent findings unconventional superconductivity CoSiTiSi heterostructures study the effect interface induced Rashba spin orbit coupling the conductance three terminal shape superconducting device calculate the differential conductance for this device within the quasi-classical formalism that includes the mixing triplet-singlet pairing due the Rashba spin orbit coupling discuss our result the light the conductance spectra reported Chiu alfor CoSiTiSi heterostructures Introduction The search for platforms that can host Majorana zero modes MZMs has been one the major topics driving current condensed matter research MZMs being localized quasiparticles that obey nonAbelian braiding statistics are the essential ingredient for topological quantum computing Early proposals for creating MZMs involve spin triplet superconductivity while almost all known superconductors belong the spin singlet class with few possible exceptions such UPt result variety ingenious heterostructures superconducting nano-wires have been proposed and observed generate the required p-wave pairing component taking advantage broken time-reversal and inversion symmetry MZM has also been proposed inside vortex topological superconductor the experimental observation MZM some the iron-based superconductors along this line and Kane proposed that proximity s-wave superconductor surface topological insulator may serve for the same purpose generate MZMs due the spin-momentum locking Their proposal has been confirmed experimentally distinguish between singlet and triplet superconductors addition nuclear magnetic resonance andspin rotation probe T-shaped proximity structure junction was proposed probe into the presence triplet superconductivity The proposed device consists two normal metal wires combined form the letter This three-terminal device connected superconductor the free end the leg see Fig shown Ref chiral p-wave ordinary p-wave state give zero bias conductance peak ZBCP response bias voltage between the open ends the bar the Recent experimental results reported Chiu have been argued consistent with the occurrence chiral p-wave pairing CoSiTiSi heterostructures Chiu support their claim with conductance spectroscopy data CoSiTiSi superconductor-normal metal tunnel junctions these heterostructures CoSi the superconducting component which becomes superconducting below The conductivity the tunnel junctions agrees with the theoretical calculations based the Blonder-Tinkham-Klapwijk BTK model for chiral p-wave superconductor However there sharp zero bias peak the conductance spectra the junction which cannot described within the BTK theory Chiu further substantiate their interpretation with conductance spectra based three terminal shaped proximity devices similar the one sketched Fig which again show ZBCPs noted Ref distinction between ordinary and chiral p-wave superconductor solely based experimental conductance spectra hardly feasible The observation hysteresis behavior the magnetoresistance below superconducting transition temperature the CoSiTiSi junctions however further vindicates their claim chiral p-wave the CoSiTiSi heterostructures The findings Ref are intriguing for few reasons The superconductivity CoSi was discovered the theoretical estimate based phonon mediated pairing appears agree well with the experimental The specific heat data below superconducting state suggests conventional s-wave pairing This material does not appear located the vicinity magnetism therefore there reason expect chiral p-wave superconductor least the bulk limit worth noting that strong spin-orbit coupling SOC exceeding the superconducting gap CoSi more than factor has been reported CoSi the same group Having mind this strong SOC propose the substrate induced Rashba SOC source p-wave pairing this system known that SOC induced pairing does not break the time reversal symmetry and the presence the SOC also leads mixing the triplet and the singlet components the context noncentrosymmetric superconductors the tunneling conductance for junctions has been studied systems with SOC However the effect the SOC and the conductance for mixed parity superconhttp://arxiv.org/abs/2101.10197v2 FIG Schematic illustration T-shaped junction The three terminal proximity device consists diffusive normal metal part attached superconductor The blue area indicates the diffusive normal metal part the device while the orange area shows the part color online ductor T-junction device not known The original T-junction study did not include the SOC and the ZBCP for chiral p-wave superconductor expected weak this paper investigate the effect the singlettriplet mixing the conductance spectra the shaped junctions the context CoSiTiSi heterostructures focus substrate induced SOC superconductor which results the pairing state where the singlet component has s-wave symmetry and the triplet component has p-wave symmetry principle triplet and singlet components can have anisotropic structures due the orbital form factors and because the bands crossing the Fermi energy derive from the orbitals Thus also consider the and pairing states which have additional orbital form factors compatible with dxy and dxy functions which lead dxy and dxy structures for the singlet components and effectivelywave and p-wave like structures for the triplet components respectively The state has been proposed for few heavy electron noncentrosymmetric systems and the state has been suggested for LaAlOSrTiO heterointerfaces Model Formalism model the CoSiTiSi shaped junction Ref terms the two-dimensional proximity devices depicted schematically Fig The transport the normal metal part assumed diffusive which the experimentally relevant regime The height and the width are very small compared its length Lxy either direction and its dimensions are assumed very small compared the coherence length hvF where and are the Fermi velocity and the superconductivity gap respectively Within the ambit these assumptions this structure can thought set two one dimensional wires joined form the shape the letter The leg this T-shaped junction attached clean superconductor The ends the horizontal section this junction are subjected bias voltage consider the case where the SOC exists the superconducting component this structure due its broken inversion symmetry The kinetic part the Hamiltonian reads HSOCk Here the electronic dispersion relation for the fermions and the SOC term HSOCk where the Rashba SOC coupling constant the effective mass and where xyz are the Pauli matrices spin space consider the Rashba SOC that induced along the growth direction which chosen the direction the T-shaped junction this case the normal the relevant interface along the axis and the SOC vector kykx ksink cosk where the angle the two dimensional momentum space Diagonalizing the Hamiltonian results splitting the original band into two helical bands with different spin structures The energies these two bands are The difference the density states and the Fermi velocities are the order where and are the Fermi momentum and the Fermi energy the original band For realistic systems the SOC energy generally very small compared the Fermi energy Therefore ignore this difference the density states and the Fermi velocities between the helical bands and take these parameters the same the original band for our subsequent calculations assume that the superconducting component confined the two-dimensional plane and that has dimensions that are very large compared the coherence length hence treat like homogeneous system and ignore any kind inverse proximity effect due the junction formation adopt the quasi-classical Keldysh formalism carry out the conductance calculations where the quasi-classical Greens function consists retarded advanced and Keldysh components Each these components matrix the Nambu-spin space denote the Greens function this space with and denotes the Greens functions the spin basis The advanced and Keldysh components can obtained from the retarded component which focus the following Following Ref the quasiclassical retarded Greens function superconductor without inversion symmetry can expressed gII gIIII fII fIIII fII fIIII gII gIIIIy where III gIII III fIII III III gIII gIII and fIII fIII The general gap structure for system with the SOC ssk ttkAk Here the SOC vector acts like the d-vector and the gap magnitude the singlet triplet component The gaps two helical bands are III sstt The angular anisotropy the gaps are embedded and The simplest case which referred sp-state where the singlet component isotropic s-wave state and the triplet component has p-wave structure Such states have been proposed for various non-centrosymmetric superconductors Apart from this the other possibilities are thestate where cos and the dp-state with sin focus sp-state which more relevant the context CoSiTiSi heterostructures The gap function parameterized where Here the parameter the ratio triplet singlet component The Cooper pairs from the superconducting side can tunnel into the diffusive normal metal and this effect included through the boundary conditions which are used solve the Usadel equations the side treat the barrier between the and the superconductor spin-independent barrier This assumption justified because the SOC very small compared the Fermi energy first calculate the retarded component the quasi-classical Greens function gRn and then construct the advanced and the Keldysh components using gRn The subscript denotes the normal metal The Usadel equations for gRn are where the diffusion constant the normal metal denotes the spatial directions and diag The normalization condition for the quasi-classical Greens function gRn These equations are supplemented the boundary conditions gRn gRny gRn where the last condition reflects current conservation The boundary condition depends the nature the gap the superconductor use the boundary condition derived Nazarov for interfaces with arbitrary transparency which was generalized for unconventional superconductors Tanaka this approach the interface modeled function potential barrier which has the transmission probability cos cos where the angle measured with respect the normal the interface which axis the geometry consider and dimensionless parameter given mHkF Here the effective mass and the Fermi momentum large value gives interface with poor transparency whereas characterizes transparent interface The boundary condition the interface can expressed yLy where the right hand side the quasiclassical Greens function the region evaluated and the ratio the normal metal resistance and the interface resistance The angular average the right hand side defined cos cos Note the angle the boundary condition measured with respect the interface normal The matrix function gnH gnH Note the boundary condition itself depends the solution the boundary calculate the differential conductance first calculate the current For the current calculation need the Keldysh component the quasiclassical Greens function gRh hgA where the advanced component and the spin resolved distribution function diagonal matrix diagfLfT fLfT fLfT fLfT where and are the transverse and the longitudinal distribution functions and the spin index the T-shaped junction bias voltage applied and the other end the voltage kept FIG Differential conductance for T-shaped junction attached superconductor under the influence Rashba SOC The parameter the ratio triplet singlet component the order parameter The interface quality parameter set The ratio lengths along the two spatial direction LyLx and the panels and respectively The differential conductance calculated the zero temperature limit zero Therefore the equilibrium spin-resolved distribution functions these two ends are xLxy xLxy Here the Fermi-Dirac distribution function and The transverse component the distribution function will the same for both spin components the normal electrode The charge current density JEx eND dTr Rxg gKxg Here the total density states the Fermi level The differential conductance can obtained evaluating the derivative the charge current density wrt the bias voltage numerically solve the Usadel equations the normal metal and with the aforementioned boundary conditions Since the boundary condition the interface involves the solutions the interface start with guess solution and obtain the final solution self-consistently Results Discussion consider good interface between and and fix value The interface barrier parameter set larger value represents good quality surface which essential for the formation sizable proximity effect Figure shows the differential conductance for the T-shaped device where the superconducting portion under the influence the substrate induced Rashba SOC for several values the parameter indicating the relative strength the triplet component The magnitude the gap Eth where Eth the Thouless energy for the half wire along the direction Eth hDLx For the proximity problem the characteristic energy scale the the Thouless energy which inversely proportional the square the device length smaller devices usually better for observing proximity effect related physics For large values the triplet component dominates this regime find that the differential conductance similar the p-wave case general for three dimensional system Rashba SOC gives sin where the polar angle Therefore triplet dominated system will have horizontal line nodes However our study consider two-dimensional system where the gaps the two helical bands are Thus the triplet dominant limit have isotropic unequal gaps two bands with opposite chiralities zero bias conductance peak ZBCP expected for chiral p-wave superconductor however expected weaker than p-wave system find that the height the peak comparable that p-wave system Unlike chiral p-wave superconductors the time-reversal symmetry not broken the case considered here The origin the peak the symmetry the induced pairing the diffusive metal the isotropic s-wave state can survive due impurity scattering which kills any other kind superconducting state the superconducting side the junction both triplet and singlet components are even functions frequency Therefore the triplet component leaks odd frequency even parity and spin triplet pairs and the odd frequency nature these induced pair gives rise ZBCP the case two helical bands with opposite chirality triplet state the spectral weight the ZBCP larger than that expected for chiral superconductor The ZBCP becomes sharper the length the leg attached the superconductor increases therefore T-shaped junction with shorter leg provides better chance ZBCP detection find that ZBCP forms long the triplet component stronger For the special case when triplet and singlet components are equal still find ZBCP the differential conductance albeit with reduced height and width Since one the bands has zero gap this limit the height the peak decreases the origin the reduced width the ZBCP for smaller the presence even frequency spin singlet and even parity pairs which comes from the singlet component the mixed parity FIG The differential conductance for T-shaped junction dp-superconductor for several values with larger singlet component The length along the direction superconducting state Such pairs reduce the density states the Fermi level which reduces the conductivity However induced pairs also increase conductivity the diffusive metal this increase comes through MakiThompson like process These two counter effects cancel zero energy The finite energy maximum the conductivity near the Thouless energy scale arises due different decay patterns these two effects The negative contribution from the loss density states decays exponentially while the Maki-Thompson like contribution decays non-exponentially over the energy scale Eth These two opposite contributions result dip the limit pure singlet superconductor the T-shaped junction the singlet dominated regime find both dip from the singlet component and weak ZBCP from the triplet component Figure shows evolution the conductance peak dip the strong singlet limit The width and height the ZBCP decreases rapidly with diminishing triplet component Next consider and states which possess anisotropic orbital components For thestate and are modeled cos For this gap function there are two line nodes angle wrt the interface normal axis Since have already shown that T-shaped junction with shorter leg length better for observing the ZBCP fix the value and consider good quality interface with and for our differential conductance calculations with anisotropic form factors Fig shows the differential conductance for T-shaped junction attachedsymmetry superconductor find qualitatively similar behavior forsuperconductor that sp-superconductor which was discussed above This qualitative similarity between and superconductors can understood examining the phase shift the gap FIG The differential conductance for T-shaped junctionsuperconductor for several values The length along the direction The orientation dxy orbital form factor shown the main figure The leg the T-junction taken along the direction and the voltage applied along the direction functions incoming and outgoing quasiparticle trajectories the interface For the dxy orbital function the incoming and the outgoing are qualitatively the same spsuperconductor The nodal line the dxy form factor angle there additional sign change due this anisotropic factor and the triplet component effectively the same for the spsuperconductor However the dxy form factor reduces the height the ZBCP the triplet dominated regime and the strong singlet regime the tiny peak that find for the superconductors smeared and the lineshape similar s-wave superconductor contrast find qualitatively different behavior for the state shown the Fig there splitting the ZBCP with reduced heights For dxy orbital factor the nodal line along the interface normal therefore for all the incoming gap functions dxy form factor gives sign change the outgoing gap function The triplet component has additional chiral p-wave factor which also gives sign change between incoming and outgoing gap functions which gets canceled the sign change from the dxy factor hence there overall sign change This qualitatively equivalent extended s-wave state For triplet dominant cases ZBCP with splitting the outcome this lack sign change case s-wave superconductor two opposite contributions the conductivity exist while the loss density states reduces the conductivity Maki-Thompson like processes result enhancement For isotropic s-wave systems these two effects cancel zero energy However the additional anisotropy from the orbital form factor may not give exact cancellation this could lead increased conductivity the zero energy compariFIG The differential conductance for T-shaped junction dp-superconductor for several values The length along the direction The orientation dxy orbital form factor shown the main figure The leg the junction taken along the direction and the voltage applied along the direction son with pure isotropic s-wave superconductor the limit strong singlet component find featureless conductivity This expected because the nodal line parallel the interface normal and such orientation proximity effect occur Concluding RemarksIn this paper have studied the conductance T-shaped junctions connected superconductor under the influence strong Rashba SOC generated the underlying substrate The d-vector the superconducting state determined the SOC The superconducting state mixed parity state with both singlet and triplet components calculated the tunneling conductance for this system within the quasiclassical formalism The effect the superconducting order included through Nazarov-Tanaka boundary conditions looked the effect the device size the zerobias conductance peak agreement with earlier work find that smaller device dimensions result larger FWHM the ZBCPs Moreover showed that both triplet and singlet components affect the conductance Specifically considered and pairing states The and states produce ZBCPs whenever the triplet component stronger than the singlet one The peak weaker the case superconductors due anisotropic dxy orbital form factor the strong singlet limit find dip structure the conductance spectrum For the sp-state the regime where finite but small triplet component co-exists with large singlet component predict weak ZBCP top the dip structure This ZBCP disappears quickly with the decreasing triplet strength For thestate the weak ZBCP disappears rapidly already when the triplet component becomes smaller than the singlet component contrast find ZBCP splitting for the dp-state which happens because the triplet component does not cause sign change the incoming and outgoing gaps Thus conclude that making interfaces with different crystallographic orientations the superconductor will useful for drawing concrete conclusions systems where anisotropic orbital form factors are likely present the context the recent experimental results CoSiTiSi heterostructures believe that the state consistent with the experiments have performed our calculations for device sizes that are comparable the experimental setup found that the triplet dominant regime the opposite chirality superconductivity the two helical bands gives ZBCP the conductance the T-junction This peak quite robust and stronger than the peak expected for usual chiral p-wave superconductor Therefore think that the CoSiTiSi heterostructure triplet dominant singlet triplet superconductor The conductance for junction comprised such triplet dominant mixed parity superconductor and normal metal junction has been studied earlier and agrees with the CoSiTiSi tunnel junction data barring the sharp feature the zero energy One the major issue with our description the CoSiTiSi heterostructures the lack the time reversal symmetry breaking TRSB that has been observed The TRSB the mixed parity superconductors has been predicted earlier however expected happen lower temperature below Twin boundaries can also cause TRSB the triplet and the singlet components are comparable magnitudes Another possible explanation for the hysteresis observed the magnetoresistance data the Zeeman field induced supercurrent superconductor with broken inversion symmetry in-plane Zeeman field gives rise supercurrent flow along the direction perpendicular think that experiments CoSiTiSi heterostructures will provide ubiquitous evidence for TRSB have considered simple one band model for the CoSi for qualitatively understanding the CoSiTiSi heterostructures However multiband system which can possible origin the TRSB leave this issue TRSB for future study conclude that the CoSiTiSi heterostructure mixed parity superconducting state with dominant p-wave component Such mix parity superconductor with dominant triplet component topologically nontrivial system and similar quantum spin hall system hosts topologically protected Andreev bound states which carry spin currents therefore constituting important platform for further research ACKNOWLEDGMENTS The authors are grateful Shao-Pin Chiu and JuhnJong Lin for helpful discussions and FCZ are partially supported NSFC grant and the priority program the Chinese Academy Sciences grant XDB and the China Postdoctoral Science Foundation under grant Work Zhejiang University was part supported the National Key Program the MOST China grant YFA and the National Science Foundation China grant fuchun@ucas.ac.cn stefan.kirchner@correlated-matter.com Read and Green Phys Rev Kitaev Physics-Uspekhi Ivanov Phys Rev Lett Kitaev Annals Physics Wilczek Nature Physics Nayak Simon Stern Freedman and Das Sarma Rev Mod Phys Lutchyn Sau and Das Sarma Phys Rev Lett Oreg Refael and von Oppen Phys Rev Lett Mourik Zuo Frolov Plissard Bakkers and Kouwenhoven Science Nadj-Perge Drozdov Chen Jeon Seo MacDonald Bernevig and Yazdani Science Volovik The Universe Helium Droplet Oxford University Pres Wang Kong Fan Chen Zhu Liu Cao Sun Schneeloch Zhong Ding and H-J Gao Science Liu Chen Zhang Peng Y-J Yan C-H-P Wen Lou Y-L Huang J-P Tian X-L Dong G-W Wang W-C Bao Q-H Wang Z-P Yin Z-X Zhao and D-L Feng Phys Rev and Kane Phys Rev Lett H-H Sun K-W Zhang L-H G-Y Wang Z-A C-L Gao D-D Guan Y-Y Liu Qian Zhou S-C F-C Zhang and J-F Jia Phys Rev Lett Mackenzie and Maeno Rev Mod Phys Asano Tanaka Golubov and Kashiwaya Phys Rev Lett S-P Chiu Tsuei S-S Yeh F-C Zhang Kirchner and J-J Lin Observation triplet superconductivity CoSiTiSi heterostructures arXiv Blonder Tinkham and Klapwijk Phys Rev Matthias Phys Rev Mattheiss and Hamann Phys Rev Tsutsumi Takayanagi and Hirano Physica Condensed Matter proceedings the Yamada Conference XLV the International Conference the Physics Transition Metals Gorkov and Rashba Phys Rev Lett Iniotakis Hayashi Sawa Yokoyama May Tanaka and Sigrist Phys Rev Vorontsov Vekhter and Eschrig Phys Rev Lett Tanaka Mizuno Yokoyama Yada and Sato Phys Rev Lett Eschrig Iniotakis and Tanaka Non-Centrosymmetric Superconductors edited Bauer and Sigrist Lecture Notes Physics Vol Springer Berlin Heidelberg Tamura and Tanaka Phys Rev Tada Kawakami and Fujimoto Journal the Physical Society Japan Yanase and Sigrist Journal the Physical Society Japan Usadel Phys Rev Lett Hayashi Wakabayashi Frigeri and Sigrist Phys Rev Frigeri Agterberg Koga and Sigrist Phys Rev Lett Frigeri Agterberg Milat and Sigrist arXiv e-prints condmat arXivcond-mat cond matsupr-con Annunziata Manske and Linder Phys Rev Zaitsev Physics Letters Nazarov Superlattices and Microstructures Tanaka Nazarov and Kashiwaya Phys Rev Lett Tanaka Nazarov Golubov and Kashiwaya Phys Rev Phys Rev Tanaka Asano Golubov and Kashiwaya Phys Rev Phys Rev Morten Brataas and Belzig Phys Rev Tanaka Asano Golubov and Kashiwaya Phys Rev Phys Rev Tanaka and Golubov Phys Rev Lett Volkov and Takayanagi Phys Rev Lett Phys Rev Asano Phys Rev Timm Rex and Brydon Phys Rev Wang and Phys Rev Lett Arahata Neupert and Sigrist Phys Rev Yip Phys Rev Edelstein Phys Rev Tanaka Yokoyama Balatsky and Nagaosa Phys Rev Sato and Fujimoto Phys Rev fuchun@ucas.ac.cn stefan.kirchner@correlated-matter.com https://doi.org/10.1103/PhysRevB.61.10267 https://doi.org/10.1070/1063-7869/44/10s/s29 https://doi.org/10.1103/PhysRevLett.86.268 https://doi.org/https://doi.org/10.1016/S0003-4916(02)00018-0 https://doi.org/10.1038/nphys1380 https://doi.org/10.1103/RevModPhys.80.1083 https://doi.org/10.1103/PhysRevLett.105.077001 https://doi.org/10.1103/PhysRevLett.105.177002 https://doi.org/10.1126/science.1222360 https://doi.org/10.1126/science.1259327 https://doi.org/10.1126/science.aao1797 https://doi.org/10.1103/PhysRevX.8.041056 https://doi.org/10.1103/PhysRevLett.100.096407 https://doi.org/10.1103/PhysRevLett.116.257003 https://doi.org/10.1103/RevModPhys.75.657 https://doi.org/10.1103/PhysRevLett.99.067005 https://arxiv.org/abs/2012.13679 https://doi.org/10.1103/PhysRevB.25.4515 https://doi.org/10.1103/PhysRev.87.380 https://doi.org/10.1103/PhysRevB.37.10623 https://doi.org/https://doi.org/10.1016/S0921-4526(97)00188-9 https://doi.org/10.1103/PhysRevLett.87.037004 https://doi.org/10.1103/PhysRevB.76.012501 https://doi.org/10.1103/PhysRevLett.101.127003 https://doi.org/10.1103/PhysRevLett.105.097002 https://doi.org/10.1007/978-3-642-24624-1 https://doi.org/10.1103/PhysRevB.99.184501 https://doi.org/10.1143/JPSJ.77.054707 https://doi.org/10.1143/JPSJ.77.124711 https://doi.org/10.1103/PhysRevLett.25.507 https://doi.org/10.1103/PhysRevB.73.092508 https://doi.org/10.1103/PhysRevLett.92.097001 https://arxiv.org/abs/cond-mat/0505108 https://doi.org/10.1103/PhysRevB.86.174514 https://doi.org/https://doi.org/10.1016/0375-9601(94)91257-2 https://doi.org/10.1006/spmi.1999.0738 https://doi.org/10.1103/PhysRevLett.90.167003 https://doi.org/10.1103/PhysRevB.69.144519 https://doi.org/10.1103/PhysRevB.70.219907 https://doi.org/10.1103/PhysRevB.72.140503 https://doi.org/10.1103/PhysRevB.73.059901 https://doi.org/10.1103/PhysRevB.72.014510 https://doi.org/10.1103/PhysRevB.72.140503 https://doi.org/10.1103/PhysRevB.73.059901 https://doi.org/10.1103/PhysRevLett.98.037003 https://doi.org/10.1103/PhysRevLett.76.4026 https://doi.org/10.1103/PhysRevB.56.11184 https://doi.org/10.1103/PhysRevB.64.014511 https://doi.org/10.1103/PhysRevB.91.180503 https://doi.org/10.1103/PhysRevLett.119.187003 https://doi.org/10.1103/PhysRevB.87.220504 https://doi.org/10.1103/PhysRevB.65.144508 https://doi.org/10.1103/PhysRevB.67.020505 https://doi.org/10.1103/PhysRevB.79.060505 https://doi.org/10.1103/PhysRevB.79.094504"
" EPJ manuscript will inserted the editor Precision measurements differential cross sections and analyzing powers elastic deuteron-deuteron scattering MeVnucleon Ramazani-Sharifabadia Ramazani-Moghaddam-Aranib Amir-Ahmadi Baileyc Deltuva Eslami-Kalantari Kalantar-Nayestanaki Kistryn Kozela Mahjour-Shafiei Mardanpour Messchendorp Mohammadi-Dadkan Stephan Stephenson and Tavakoli-Zaniani Department Physics University Tehran Tehran Iran KVI-CART University Groningen Groningen The Netherlands Department Nuclear Physics Faculty Physics University Kashan Kashan Iran Center for Exploration Energy and Matter Indiana University Bloomington USA Institute Theoretical Physics and Astronomy Vilnius University Vilnius Lithuania Department Physics School Science Yazd University Yazd Iran Institute Physics Jagiellonian University Krakow Poland Institute Nuclear Physics PAS Krakow Poland Department Physics University Sistan and Baluchestan Zahedan Iran Institute Physics University Silesia Chorzow Poland Received date Revised version date Abstract present measurements differential cross sections and analyzing powers for the elastic scattering process The data were obtained using MeV polarized deuteron beam Cross sections and spin observables the elastic scattering process were measured the AGOR facility KVI using two independent setups namely BINA and BBS The data harvest setups are excellent agreement with each other and allowed carry out thorough systematic analysis provide the most accurate data elastic deuteron-deuteron scattering intermediate energies The results can used confront upcoming state-of-the-art calculations the four-nucleon scattering domain and will thereby provide further insights the dynamics threeand four-nucleon forces few-nucleon systems Key words deuteron-deuteron scattering elastic channel vector and tensor analyzing powers nuclear forces PACS Introduction Understanding the degrees freedom that describe nuclear forces great importance make progress nuclear physics The first major breakthrough came when Yukawa presented the description the nucleonnucleon force the exchange massive mesons analogy the exchange massless photons describing successfully the electromagnetic interaction More recently various phenomenological nucleon-nucleon potentials have been derived based Yukawas idea Some these potentials were successfully linked the underlying fundamental theory quantum chromodynamreza ramazani@ut.ac.ir ramezamo@kashanu.ac.ir Present address American Physical Society Physics Ellipse College Park USA ics Precision measurements obtained from nucleonnucleon scattering data are strikingly well described these modern potentials compelling apply the high-precision potentials systems composed least three nucleons Rigorous Faddeev calculations the binding energy the simplest three-nucleon system triton underestimate the experimental data This observation shows that calculations based solely potentials are not sufficient describe systems that involve more than two nucleons This has led the notion the three-nucleon force concept that was introduced already the early days nuclear physics Primakoff and Holstein Greens function Monte Carlo calculations based the potential complemented with the three-nucleon potential demonstrated the necessity the describe the experimental data for the binding Ramazani-Sharifabadi Title Suppressed Due Excessive Length energies light nuclei Moreover rigorous Faddeev calculations based modern potentials show large discrepancies with cross section data elastic nucleondeuteron scattering The inclusion effects partly resolves these deficiencies There are now large number evidences revealing the importance effects the last decades many nucleon-deuteron elastic and breakup scattering experiments various energies below the pionproduction threshold have provided extensive database for the study effects The addition effects particular the role the resonance reduces significantly the discrepancies between differential cross-section data and corresponding calculations excluding effects The situation for spin observables vastly different For instance the inclusion effects for the vector analyzing power the elastic channel the intermediate energies gives better agreement between data and theory while for the tensor analyzing power ReT the discrepancies are not removed adding effects the model The inclusion effects even deteriorates the agreement between model predictions and the data for the vector analyzing power the proton the proton-deuteron breakup reaction configurations that correspond small relative energies between the two outgoing protons These observations imply that spindependent parts effects are not yet well understood Although the three-nucleon system the cleanest system study effects since only and forces can contribute and observables can calculated ab-initio manner the influence effects are general small system Only specific parts the phase space three-nucleon scattering processes effects become significant well-known example such phase space appears scattering angles corresponding the minimum the differential cross section elastic scattering spin observables significant effect can also seen for break-up configurations corresponding small relative energies between the two outgoing protons Alternatively and this the focus this paper one may investigate the four-nucleon system which effects could significantly enhanced Deuteron-deuteron scattering system rich laboratory study effects because its variety final states observables and kinematical configurations Compared the amount available data the scattering domain the database the system very limited Most the data cover the very lowenergy regime below the threeand four-body breakup threshold Although calculations these low energies are very reliable the effect the very small Therefore the low-energy realm not the most attractive regime study rigorously the dynamics NFs Ab-initio theoretical calculations for four nucleon systems are still limited beam energies below MeV intermediate energies below the pion-production threshold the experimental database very scarce Despite the fact that ab-initio calculations are still development this energy regime the prospects studying the structure forces and possibly higher-order four-nucleon force effects look promising Recent theoretical approximations for deuteron-deuteron scattering are able reasonably predict the experimental results the quasi-free regime However one should consider the finalstate interactions spectator neutrons identify the limit correctly Besides charge symmetry breaking studies CSB reaction reveal the necessity theoretical calculations elastic scattering process provide unambiguous formulation the initial-state interaction this energy regime singlescattering approximation used which one nucleon scatters from the opposite deuteron before recombines reform the original deuteron This paper presents measurements the differential cross section and spin observables the elastic scattering process for deuteron-beam energy MeVnucleon The data were obtained making use vectorand tensor-polarized deuteron beam that was provided the AGOR facility KVI Groningen the Netherlands Two experimental equipments located two different beam lines were used measure independently the various observables scattering namely the Big-Bite Spectrometer BBS and the Big Instrument for Nuclear-Polarization Analysis BINA These setups bring complementary features one BINA covering large phase space particularly using liquid deuterium target leading less background The other BBS possesses excellent momentum resolution but with moderate coverage using solid target with more precise knowledge the target thickness the cost larger background These two sets measurements combined have provided good experimental database that can used benchmark for future ab-initio calculations This paper addresses the analysis these two independent datasets The results presented here are the most precise and accurate data the process intermediate energies Experimental setups This experiment was performed with two different setups BINA and BBS the following details both setups relevant for the present paper will presented Detailed discriptions are presented respectively Common source and accelerator facilties The two experiments were conducted using AGOR facility KVI The measurement BINA took place the week after the BBS data taking BINA has the ability identify and measure all reaction channels the deuterondeuteron scattering process simultaneously while BBS Ramazani-Sharifabadi Title Suppressed Due Excessive Length measures the hadronic channels with particles emerging from the two-body final states Vectorand tensorpolarized unpolarized deuteron beams were produced the atomic Polarized Ion Source POLIS with nominal polarization values between the theoretical values and accelerated the AGOR cyclotron energies MeVnucleon The polarization the deuteron beam was monitored for different periods the experiment and found stable within statistical uncertainties BINA Figure shows sketch BINA The setup consists two parts forward wall and backward ball The forward wall consists multi-wire proportional chamber MWPC determine the scattering angles the particles twelve-vertically mounted plastic scintillators with thickness and ten horizontally mounted E-scintillators with thickness The E-scintillators are placed cylindrical shape where the target positioned the axial symmetry the cylinder Although the E-E hodoscope provides the possibility perform particle identification the information from the detector was not used this experiment visual inspection after the experiment these scintillators were observed damaged Therefore the E-E detectors could not provide the PID information for all scattering angles Photomultiplier tubes PMTs were mounted both sides each E-scintillator Signals from these PMTs are used extract the energy and time-of-flight TOF each scattered particle The TOF information used perform PID The MWPC covers scattering angles between and with full azimuthal angle coverage and with limited azimuthal angle coverage The MWPC has resolution for the polar angle and between and for the azimuthal angle depending the scattering angle The detection efficiency the MWPC for deuteron with energies corresponding the reaction interest typically The backward ball BINA made phoswich scintillators that were simultaneously used detector and scattering chamber with scattering-angle coverage between and and nearly full azimuthal coverage For more details BINA refer The deuteron beam with typical current bombarded liquid-deuterium target that was mounted inside the scattering chamber BINA The thickness the target cell was with uncertainty The scattering angles energies and partly time flights the final-state deuterons were measured the multi-wire proportional chamber MWPC and scintillators BINA Faraday cup was mounted the end the beam line monitor the beam current throughout the experiment The current meter the Faraday cup was calibrated using current source with uncertainty small offset the readout the current was observed with value around see Sec Forward WallTarget Beam Backward Ball MWPC Beam pipe Fig sketch the various components the BINA setup The elements the right side show side view the forward part BINA including the multi-wire proportional chamber MWPC array twelve thin plastic E-scintillators followed ten thick segmented E-scintillators mounted cylindrical shape the left side the backward part BINA depicted composed phoswich scintillators glued together form the scattering chamber BBS The Big-Bite Spectrometer BBS QQD-type magnetic spectrometer with K-value MeV and solid angle msr changing the position the quadrupole doublet with respect the dipole magnet while the distance between the object target and the dipole remains the same the momentum-bite acceptance can changed from the solid angle changes from msr simultaneously The BBS consists scattering chamber containing target ladder large slit wheel containing several entrance apertures including sieve slit for angle reconstruction two sets quadrupole magnets for beam focusing large dipole magnet for momentum selection two sets x-u plane wire-chamber detectors and scintillator plane which used generate the event trigger diagram the BBS shown Fig the BBS setup different thick thin sets and carbon targets were used for different ranges lab angles The carbon targets were used the forward range spectrometer angles able subtract the background generated deuterons elastically scattered from carbon the target For large angles several layers solid were combined resulting total thickness mgcm For small angles and Ramazani-Sharifabadi Title Suppressed Due Excessive Length MWPCs Carbon analyzer Scintillators VDCs and FPPFPDS target Fig sketch the main features the BBS setup the target thickness was mgcm The thickness the carbon target for large angles was mgcm for small angles was mgcm The scattering chamber the BBS consisted large cylindrical chamber containing the targets and essentially forming the pivot point around which the device covers the scattering angles between and during the data taking For the beam integration large copper Faraday cup was used for the angles larger than where the unscattered beam could hit the wall the scattering chamber For small scattering angles less than the unscattered beam was within the acceptance BBS and entered the region the quadrupole magnets Therefore separate Faraday cup mounted between the quadrupole magnets and for the beam integration this region detailed description the BBS setup presented Event selection and data analysis method this section the analysis procedures both experiments related the BINA and BBS setups are described separately Detailed discriptions are presented respectively BINA During data taking with BINA various hardware triggers with different down-scale factors were implemented that were dedicated specific hadronic final state deuteron-deuteron scattering select events originating from elastically scattered deuterons two triggers were importance The first one referred the coincidence trigger registered events for which there was least one signal from the forward wall scintillators coincidence with least one signal originating from the backward wall This trigger was down-scaled factor two The hardware thresholds for detection particle were typically set around MeV Although with the coincidence trigger were able cover large part the angular distribution the reaction whereby both deuterons the final state were detected observed significant drop the detection efficiency for low-energetic deuterons that scatter towards the backward ball due energy losses those particles the liquiddeuterium target The data selected with the coincidence trigger were used extract the spin observables since detection inefficiencies cancel out the analysis extract the differential cross section exploited second trigger the so-called single trigger This trigger downscaled factor was built from logical all the discriminated signals the scintillators BINA and thereby not biased the response the backward ball The data from the coincidence trigger were calibrated and further preprocessed requiring that the relative angles the reconstructed particles hitting the forward wall and backward ball match the correlation that expected from kinematical considerations for the elastic deuterondeuteron scattering process Cuts were applied meet relative opening angle and coplanar configuration with respect the azimuthal angles After applying these angular cuts with window major reduction around backgrounds from other hadronic final states such breakup and nucleon-transfer reactions was obtained Figure shows the correlation between energy and scattering angle deuterons detected the forward wall BINA after the aforementioned event selection The solid line represents the expected kinematical locus for the elastic deuteron-deuteron scattering seen elastically scattered deuterons can easily observed and distinguished from background channels The data below the elastic events reveal another clear correlation which has been identified events belonging the neutrontransfer channel count the number events that originate from the elastic process the center-of-mass energy for each reconstructed particle calculated from its energy deposit and scattering angle and corresponding histogram generated intervals the scattering angle and separated for the various polarization states the beam Figure depicts the center-of-mass energy distribution that has been obtained using the single trigger The upper spectrum shows the raw response after calibration and for particles that scatter but without any further conditions For the lower spectrum coincidence with the backward ball was required addition using the kinematical cuts discussed earlier but from data taken with the single trigger The solid lines are the result fit through the data based Gaussian-distributed signal Ramazani-Sharifabadi Title Suppressed Due Excessive Length deg Counts Fig The correlation between the reconstructed energy and scattering angle the particles that were detected the forward part BINA with coincidence requirement with the backward ball The solid line represents the kinematical locus for the elastic deuteron-deuteron scattering process MeVcmE Fig Spectrum the center-of-mass energy particles hitting the detectors the forward wall Data are obtained using the single trigger The scattered particles are confined polar angles For the lower spectrum coincidence condition imposed the event selection The solid lines show the results leastfit based Gaussian signal and th-order polynomial background distribution The background contribution indicated the dashed lines The the fit for the upper spectrum and for the lower one combined with th-order polynomial representing the backgrounds The background component the fit indicated the dashed lines clear peak can observed both cases corresponding unambiguously the channel interest The difference between the integrals the signal distributions before and after applying the coincidence condition excluding inefficiencies the ball less than The coincidence requirement reduces significantly the background contribution Monte Carlo simulations showed that the remaining background mostly due hadronic interactions elastically scattered deuterons the scintillator extract cross sections the number counts passing the kinematical criteria has been corrected for efficiencies the system such live-time MWPC efficiencies hadronic interactions and the down-scale factor that comes from triggers The average live-time the data acquisition BINA around Events from the elastic reaction that suffered from hadronic interactions not give clear peaking structure the energy spectrum and are therefore not easily separated from other background channels did not count these events and corrected for their loss Using GEANT-based Monte Carlo simulation estimated loss for the energy range interest The cross sections are corrected for this effect accordingly Vector and tensor polarized beams make possible measure spin observables Using parity conservation the cross section for reaction given the following equation pZAy cos pZZAzz pZZ Azz Ayy cos where and are polar and azimuthal angles the scattered deuteron respectively the vector analyzing power while Azz and Ayy are the tensor analyzing powers pZZ represents the vector tensor polarization the beam the effective cross section obtained for data taken with unpolarized beam These effective cross sections correspond the number counts normalized the accumulated and dead-time corrected charge Please note that first order the efficiencies cancel taking the ratio between and Finally normalization factor and should equal one the ideal case Considering free parameter fluctuates around one with value that considered systematic uncertainty for the normalization procedure Experimentally however evaluated possible systematical differences the extraction the effective cross sections and accommodated These may due small differences detection efficiencies beam-current measurements between data taken with unpolarized and polarized beams For the extraction the analyzing powers analyzed data taken with the coincidence trigger and enforcing the selection criteria described above note that the background using the coincidence conditions very small extracted the analyzing powers with two different methods which both lead compatible results within the uncertainties the first method assume that the beam polarization purely vector and pZZ purely tensor and pZZ Therefore the corresponding terms are kept and the other terms are set zero can seen the asymmetry ratio polarized un-polarized cross section function cos cos for the case pure vector tensor polarized beam see Fig Therefore vector analyzing power extracted from the amplitude cos the same way tensor analyzing powers Azz and Ayy are extracted from the off-set cos from one and its amplitude respectively estimate the systematic uncertainty due the possible impurity the vectorRamazani-Sharifabadi Title Suppressed Due Excessive Length deg Fig Asymmetry ratio cross section for polarized over unpolarized beam function for pure-vector polarized beam top panel and pure tensor polarized beam bottom panel Scattering angle elastically scattered deuteron The reduced for the top bottom panel tensor-polarized beam the second method applied the second method suppose that the pure-vector tensor polarized beam not actually pure-vector tensor and pZZ other words the pure-vector tensor polarized beam contaminated with another polarization say the tensor vector polarization Therefore including all the terms used fit the asymmetry ratio polarized un-polarized cross section beam for vector and tensor analyzing powers described before the analyzing powers can again extracted from the amplitudes the cos and cos functions well the offset cos function from one The difference between the two results considered the systematic uncertainty due the possible impurity the beam polarization The results the first method considered the final results see Sec verify the procedure extracting the differential cross sections and analyzing powers the reaction measured and analyzed the reaction well The same procedure was used analyze the data the well-studied reaction which were obtained using target and with the same setup and beam conditions was applied the study the reaction Differential cross sections and analyzing powers for the reaction are presented Fig each panel the results this analysis are represented filled circles The error bars indicate the statistical uncertainties and the gray bands represent the systematical errors detailed description the related systematic uncertainties presented The open triangles show the results cross sections measured RCNP The open circles and filled triangles show the analyzing powers data taken KVI and open rectangles are those taken RIKEN The solid curves show the results coupled-channel calculation the Hannover-Lisbon theory group based the CD-Bonn potential including the Coulomb interaction and intermediateisobar The dotted lines represent results similar calculations excluding theisobar note that the effects are predicted small and therefore the results the presented Faddeev calculations based the high-precision potential are expected accurately describe the experimental data addition the results are compared with the results rough approximation based the lowest-order terms the Born series expansion the Alt-Grassberger-Sandhas AGS equation for three-nucleons interaction using CD-Bonn potential the dashed lines The comparison shows that the Born approximation not very good three-body systems this energy and therefore not expect that such approach will provide good description the four-body scattering process see Sec worth noting that the quality the Born approximation improves with increasing the energy andor small scattering angles the lowest-order terms become dominant all observables Our measurements for the reaction are excellent agreement with previously published data and with state-of-the-art calculations lending thereby confidence the analysis procedure and our estimates systematic uncertainties BBS the following the analysis procedure the BBS data described Details the analysis methods related the BBS data are presented The differential cross section and spin observables were extracted various scattering angles counting elastically scattered deuterons for various polarization states the beam access different scattering angles the spectrometer was moved around the target The quadrupole and dipole fields were changed according the kinematics the related reaction focus and bend the particles interest and bring them the detector plane this case one focal point was produced via combination quadrupole and dipole fields for scattered particle with given momentum Therefore the solid angle spanned particles they scatter from the target inside the scattering chamber were determined defining aperture front the spectrometer For this purpose seive slit aperture fitted into the slit wheel the BBS containing several pre-drilled holes was used during several runs the experiment With this slit system the optical coefficients BBS were fitted and the system was therefore calibrated for various settings The main background sources are the events including deuterons elastically inelastically scattered from Carbon These events are appeared the detector plane along with the events interest subtract the background applied two techniques For the runs with discernible Ramazani-Sharifabadi Title Suppressed Due Excessive Length CDBonnC CDBonnC Born Approx BINA RCNP RIKEN KVI KVI deg Fig Differential cross section and analyzing powers the elastic channel the reaction that were taken with deuteron beam MeVnucleon each panel the data taken with BINA are indicated with filled circles whereby the error bars are statistical The open triangles show the cross section results obtained RCNP The open circles and filled triangles show the analyzing powers data taken KVI and open rectangles are those obtained RIKEN The solid curves show the results coupled-channel calculation the Hannover-Lisbon theory group based the CD-Bonn potential including the Coulomb interaction and intermediateisobar The dotted lines represent results similar calculation excluding theisobar The dashed lines represent the results rough approximation based the lowest-order terms the Born series expansion the Alt-Grassberger-Sandhas AGS equation using CD-Bonn potential The gray band shows the systematic error each panel background structure due the Carbon the target the procedure background subtraction similar that described for the event selection BINA For the runs which clear background structure due the Carbon the target was present the separate Carbon data from the Carbon target which were taken during the experiment were used For each these runs the corresponding Carbon data data which were taken with exactly the same spectrometer settings and beam energy but with solid carbon target were analyzed using the same parameters the reaction data interest Finally obtain the differential cross section for each the five beam polarization states the extracted number counts after background subtraction corrected for the efficiencies the system such live-time and wire chamber efficiencies knowing the polarized and unpolarized cross sections for each the five beam polarization values could then calculate the unpolarized cross section and analyzing powers and Ayy using through simple matrix inversion have five equations and only three unknowns the unpolarized cross section and Ayy Therefore the analyzing powers are obtained from the polarized cross sections using matrix inversion and their statistical errors determined using standard error propagation techniques Generally there were almost always five good polarized cross sections available and therefore this was over-determined system however for few runs only three four polarization states were available which case the matrix inversion was reduced only include the existing polarized cross sections Systematic uncertainties The common systematic uncertainties between the two experiments well those specifically for BINA and BBS setups are separately presented the following subsections Common sources systematic errors The main common source systematic error comes from the uncertainty the measurements the reaction extract the polarization that around The results Ayy measurements obtained from BBS are also used estimate offset the readout the current The offset was determined minimizing the reduced whereby offset the current introduced Ramazani-Sharifabadi Title Suppressed Due Excessive Length free parameter using the comparison between the results the Ayy from the elastic channel scattering coming from the BINA and those coming from the BBS The error obtained evaluating the distribution function the offset The intersection point this distribution with value that one unit larger than its minimum has been used determine the uncertainty the offset The systematic error arising from the measurement the beam current using Faraday cup leads small offset the readout the current BINA One the systematic uncertainty the cross section measurement attributed the thickness the liquid deuterium target estimated corresponding error due the bulging the cell The size bulging was first estimated via measurement the target thickness function pressure room temperature The actual target thickness was obtained comparing the cross section measurements KVI between solid and liquid targets and the difference considered the uncertainty due the thickness measurement Other systematic uncertainties come from the beam luminosity using precision current source the MWPC efficiency for deuterons which was obtained using unbiased and nearly background-free data sample the elastic scattering process and the errors the correction factor for losses due hadronic interactions the detector For deuterons this error extracted from the difference between the measured and simulated deposition deuteron energy the forward wall BINA The uncertainty the extraction the differential cross sections due the offset current around estimate the systematic uncertainty due the background model used the and orders polynomial fit-functions instead the order polynomial representing the backgrounds The maximum difference between the results are considered the systematic uncertainty due the background model which around The polarization deuteron beam was monitored with Lamb-Shift Polarimeter LSP the lowenergy beam line and measured with BINA after beam acceleration the high-energy beam line measuring the asymmetry the elastic deuteron-proton scattering process The vector and tensor polarizations the deuteron beam BINA were found and pZZ respectively whereby the errors include uncertainties the analyzing powers elastic deuteron-proton scattering should remarked that only negative polarization states were used since the number events obtained with that polarization state much larger than those obtained with the opposite polarization state The errors were extracted employing constant-line fit through the measured polarization values function center-of-mass angle the case measuring analyzing powers systematic uncertainty comes from the normalization procedure considering the factor free parameter This error turned out around Moreover the maximum shift the results Ayy and Azz due the offset current around and respectively while the measured values these observables vary between and respectively The systematic error due the possible impurity the beam polarization negligible for the vector analyzing powers and estimated about absolute for the tensor analyzing powers BBS Systematic errors the measurement the differential cross sections originate mainly from the errors the knowledge the target thickness and the calibration the Faraday cup was already stated the error the target thickness for the elastic reaction was around The errors the areal density measurements which the mass the material divided its area with the unit mgcm come from both mass measurement errors and those from the measurements the size the target The error the calibration the Faraday cup was estimated These components added quadrature were applied overall scale factor systematic for the cross sections yielding total normalization error about for the elastic reaction The polarization states the deuteron beam the BBS were measured with the Ion-Beam Polarimeter IBP and found follows vector plus vector minus tensor plus and tensor minus The main source systematic uncertainty this method comes from the analyzing powers measurements the elastic reaction while using IBP The polarization values for each state were measured different beam energy ranges and found consistent within the statistical uncertainties The main sources systematic error for the analyzing powers include the uncertainty due beam polarization measurements and pyy and the total calibration error The calibration errors for Ayy are found around These errors introduce overall scale factor since the beam polarization and initial polarimetry calibration apply all angles Details systematic studies are presented Experimental results Figure shows the measured differential cross sections and analyzing powers for the elastic deuteron-deuteron scattering The results BINA data are presented filled circles and the results data taken BBS setup are shown open circles The light dark gray band each panel shows the systematic uncertainty the Ramazani-Sharifabadi Title Suppressed Due Excessive Length BINA BBS CDBonn BINA Sys Err BBS Sys Err deg Fig Differential cross section and analyzing powers the elastic channel the reaction are shown with statistical errors for each point The total systematic uncertainty related BINA BBS results shown with light dark gray band for each panel The results BINA data are shown filled circles and those for the BBS data are presented open circles The solid lines are the result calculation based the lowest-order terms the Born series expansion the Alt-Grassberger-Sandhas equation for four-nucleons interaction using CD-Bonn potential BINA BBS data and the error bars represent the statistical errors which are smaller than the symbol size for most the data points discussed before the results the Ayy measurement obtained from BBS were used normalize the offset the current readout and hence the corresponding systematic error the same for both setups Therefore just one gray band shown Fig The solid lines are the results rough approximation based the lowest-order terms the Born series expansion the Alt-Grassberger-Sandhas equation for four-nucleons interaction using CD-Bonn potential The comparison between the results the two experiments namely data taken from BINA and BBS setups indicates that both data sets are very good agreement within the uncertainties But comparing the experimental data with the theoretical approximation shows contradictions specially the results the analyzing powers Aside from the normalization the results the differential cross section the theoretical prediction follows least the shape the experimental data the case analyzing powers the comparison shows contradictory results indicating defects the spin parts theoretical calculations the scattering amplitude already mentioned the comparison between the results exact calculations and those coming from Born approximation Fig indicates that this approximation not very suitable for the reaction this energy range and therefore expect observe discrepancies between Born approximation and the experimental data the reaction Fig fact Born approximation may provide reasonable estimation for observables higher energies and small angles but not reliable the considered energy and angle regime this paper indicates that exact theoretical calculations four-body systems are necessity reasonable comparison with the experimental data Summary summary have analyzed the elastic channel deuteron-deuteron scattering Ramazani-Sharifabadi Title Suppressed Due Excessive Length MeVnucleon Two experiments were performed with two independent setups namely BINA and BBS which were located KVI Groningen the Netherlands Cross sections and analyzing powers were obtained for large angular range the phase space excellent agreement found between the measured differential cross sections and analyzing powers both experiments for the angular range which they overlap The experimental results are also compared with theoretical approximation based lowest-order terms the Born series expansion using CD-Bonn potential The very poor agreement between the experimental data and theoretical approximations shows the necessity ab-initio calculations the four-body systems intermediate energies ACKNOWLEDGMENT The authors acknowledge the work the cyclotron and ion-source groups KVI for delivering high-quality beam used these measurements The present work has been performed with financial support from the Nederlandse Organisatie voor Wetenschappelijk Onderzoek NWO This work was partly supported Iran National Science Foundation INSF research project under References Yukawa Proc Phys Math Soc Jpn Coon Phys Rev Epelbaum Phys Rev Rentmeester Phys Rev Lett Wiringa Smith and Ainsworth Phys Rev Primakoff and Holstein Phys Rev Pieper Pandharipande and Wiringa Phys Rev Witala Phys Rev Lett Ermisch Phys Rev Lett Ermisch Phys Rev Ermisch Phys Rev Sakai Phys Rev Lett Sekiguchi Phys Rev Sekiguchi Phys Rev Lett Postma and Wilson Phys Rev Amir-Ahmadi Phys Rev Kuroda Nucl Phys Mermod Phys Rev Igo Nucl Phys Adelberger and Brown Phys Rev Mardanpour Eur Phys Stephan Phys Rev Shimizu Nucl Phys Hatanaka Eur Phys Stephenson Phys Rev Ramazani-Moghaddam-Arani Phys Rev Ramazani-Moghaddam-Arani Few-Body Syst Kistryn Phys Rev Kistryn Phys Rev Kistryn Phys Lett Kalantar-Nayestanaki Nucl Instrum and Meth Phys Res Mardanpour Phys Lett Stephan Phys Rev Ramazani-Sharifabadi Eur Phys Ciepa Phys Rev Ramazani-Sharifabadi Eur Phys Tavakoli-Zaniani Eur Phys Shimizu Phys Rev Kalantar-Nayestanaki Rep Prog Phys Nemoto Phys Rev Phillips Phys Rev Viviani Phys Rev Lett Fisher Phys Rev Deltuva Phys Rev Deltuva Phys Rev Deltuva Phys Rev Lett Deltuva Phys Rev Lazauskas Phys Rev Deltuva Phys Rev Deltuva Phys Lett Deltuva Phys Rev Bechtold Nucl Phys Alderliesten Phys Rev Garcon Nucl Phys Elster Phys Rev Uzu Phys Rev Deltuva Phys Rev Deltuva Phys Rev Stephenson Phys Rev Lett Micherdzinska Phys Rev Ramazani-Sharifabadi PhD thesis University Groningen Bailey PhD thesis Indiana University Friedrich Polarized beams and polarized gas targets World Scientific Singapore Kremers Polarized Gas Targets and Polarized Beams AIP Conj Proc Ramazani-Moghaddam-Arani Phys Rev Mardanpour PhD thesis University Groningen Kalantar-Nayestanaki Mulder and Zijlstra Nucl Instrum and Meth Phys Res van den Berg Nucl Instrum and Meth Phys Res Ramazani-Moghaddam-Arani PhD thesis University Groningen Bieber Nucl Instrum and Meth Phys Res Kremers Nucl Instrum and Meth Phys Res Ohlsen Nucl Instr Meth Deltuva Phys Rev Introduction Experimental setups Event selection and data analysis method Systematic uncertainties Experimental results Summary ACKNOWLEDGMENT"
" MOCK MODULAR FORMS WITH INTEGRAL FOURIER COEFFICIENTS YINGKUN AND MARKUS SCHWAGENSCHEIDT Abstract this note explicitly construct mock modular forms with integral Fourier coefficients evaluating regularized Petersson inner products involving their shadows which are unary theta functions weights and addition also improve the known bounds for the denominators the coefficients mock modular forms whose shadows are holomorphic weight one cusp forms constructed Hecke Introduction his groundbreaking thesis Zwegers discovered the modular property Ramanujans mock theta functions completing them with real-analytic functions whose images under the lowering operator are essentially complex conjugates weight unary theta functions the sense Bruinier and Funke these completions are harmonic Maass forms weight whose images under the differential operator are unary theta functions weight The holomorphic part andimage harmonic Maass form are called mock modular form and its shadow see establish the modular property Ramanujans classical mock theta functions Zwegers gave three different constructions these weight harmonic Maass forms using Appell-Lerch sums indefinite theta functions and Fourier coefficients meromorphic Jacobi forms respectively Bringmann and Ono proved that generating series certain partition numbers yield mock modular forms weight whose shadows are linear combinations unary theta functions the case weight mock modular forms with holomorphic theta functions shadows the prominent example the generating series Hurwitz class numbers that appeared the seminal work Hirzebruch and Zagier Building the work Zwegers the paper also constructed such mock modular forms and related them q-series For arbitrary unary theta function weight Bruinier and the second author gave different construction itspreimage using regularized theta lifts and expressed the Fourier coefficients the holomorphic part terms values modular functions From these constructions one can apply the theory complex multiplication show that these Fourier coefficients are rational drawback the construction from the fact that does not yield explicit bound the denominators the coefficients Date January http://arxiv.org/abs/2101.05583v1 YINGKUN AND MARKUS SCHWAGENSCHEIDT some cases Charollois and the first author constructed mock modular forms whose shadows are weight unary theta functions and whose coefficients are simple finite sums rational numbers particular they obtained explicit bounds the denominators the coefficients the present article give another constructionpreimages weight and unary theta functions and show that their Fourier coefficients are rational numbers with explicitly bounded denominators Let explain our results more detail For denote CZNZ the group ring spanned the formal basis symbols for ZNZ Then for the vector-valued unary theta function mod nNZh with holomorphic modular form weight for the Weil representation MpZ see Section Our first main result follows Theorem Let There exists mock modular form weight with shadow such that has integral Fourier coefficients There exists mock modular form weight with shadow such that has integral Fourier coefficients Remark usual the holomorphic part harmonic Maass form weight for the complex conjugate the Weil representation MpZ Remark Here trick reduce the denominator Given two mock modular forms with the same shadow such that Mjfj has integral Fourier coefficients for can find such that gcdMM Then aMfaMfgcdMM mock modular with shadow and the denominators its coefficients are bounded gcdMM The denominator bounds obtained above can used give denominator bound the Weyl vectors for Borcherds products signature see which closely related the orders the multiplier systems such Borcherds products Also the rational Fourier coefficients Theorem appear other formulas such the Fourier coefficients mock modular forms with binary theta functions shadows and values higher Greens functions denominator bound have proved here would make precise the fields definition the algebraic values appearing those formulas For the proof Theorem will compute for any weakly holomorphic modular form weight for the regularized Petersson inner product reg lim dudv The order the multiplier system Borcherds product always finite see MOCK MODULAR FORMS where the usual fundamental domain for SLZ truncated the height and denotes the natural hermitian pairing CZNZ see Section From this will reconstruct using Serre duality see Proposition The basic idea compute the regularized Petersson inner product use the identity and realize special value signature theta function Then the inner product reg can viewed special value regularized theta lift the weakly holomorphic modular form which can evaluated using the methods developed Borcherds and Bruinier make the argument rigorous will implement this idea for vector-valued forms This technicality causes have the factors and the theorem above which could reduced certain cases see Remark refer the reader Section for the details the proof Theorem Note that this idea has been used when replaced holomorphic binary theta function produce harmonic Maass forms weight one The mock modular form from Theorem will constructed explicitly the proof the theorem though not canonical and involves choosing suitable lattice primitive isotropic vector and its dual see slightly modifying the method above will also give simpler formulas for mock modular forms with shadow Section give impression include special case the introduction Proposition Let the Hurwitz class numbers with Then Hnqn Nma Nma with the functions defined satisfies otherwise satisfies otherwise The proposition follows from Propositions and below There construct for any explicit mock modular form with shadow Specializing and using that the generating series Hurwitz class numbers mock modular form with shadow see easily obtain Proposition comparing the first few Fourier coefficients The first identity can probably derived from the classical results whereas the second seems new Note that for Proposition also YINGKUN AND MARKUS SCHWAGENSCHEIDT produces the following well-known mock modular form see odd abqab whose shadow Using the same idea the proof Theorem can also improve denominator bound for certain weight one harmonic Maass forms Let integral ideal real quadratic field with ring integers and odd ray class group character conductor with Nmm which view function integral ideals extending with Hecke associated the holomorphic weight one level eigenform aOF aqNma Charollois and the first author showed that there mock modular form with shadow satisfying aClF Nman log log with prime Here the fundamental unit the subring generated the values and have chosen set representatives the class group ClF The constant comes from bounding the denominator mixed mock modular form weight Theorem can now improve follows Theorem the notations above can take Example The constant above can sometimes reduced LetD and define sgn for integral ideal with given mod mod otherwise There mistake where should replaced This affects Theorem where should replaced DMM MOCK MODULAR FORMS Then aOF Nma Furthermore define log with Then John Duncan asked the function log aOF aqNma mock modular form with shadow This indeed the case and follows from the results will give the details Section The paper organized follows start with section the necessary preliminaries about vector-valued harmonic Maass forms for the Weil representation unary theta functions and their connection the Dedekind eta function and the relation between the evaluation regularized inner products and mock modularity Section evaluate several regularized theta lifts signature Sections and are devoted the proofs Theorem and Theorem Finally Section give explicit constructions mock modular forms whose shadows are unary theta functions Acknowledgement thank John Duncan for sharing the observation Example Preliminaries Modular forms for the Weil representation recall some facts about harmonic weak Maass forms for the Weil representation associated with even lattice from Let MpR the metaplectic two-fold cover SLR consisting elements with SLR and holomorphic with Let MpZ MpR denote the inverse image SLZ under the covering map MpR SLR generated and let the subgroup generated Let even lattice with quadratic form signature the dual lattice and the associated finite quadratic module discriminant form which becomes quadratic form valued Let the associated bilinear form Moreover let the discriminant kernel which the subgroup the orthogonal group which acts trivially For convenience use denote the lattice with the quadratic form YINGKUN AND MARKUS SCHWAGENSCHEIDT The group ring CAL hAL Ceh naturally MpZ-module via the Weil representation defined eQheh LSeh where put eix for Despite the notation only depends the finite quadratic module There natural hermitian pairing CAL given and zero otherwise With respect this pairing unitary representation real-analytic function CAL called modular weight with respect kLA fAz for all MpZ and denote the spaces harmonic Maass weakly holomorphic holomorphic and cuspidal forms weight for HkL MkL SkL respectively More generally for any representation MpZ the subscript the notation above will replaced Every HkL can written uniquely where holomorphic and has Fourier expansion the form hAL mZQh hmq with coefficients may assume that sgnL mod since otherwise the action sgnL implies that HkL trivial Moreover under this assumption the coefficients above satisfy the symmetry sgnL for every and The antilinear differential operator defines surjective map HkL see Theorem holomorphic CAL-valued series called mock modular form weight with shadow the holomorphic part harmonic Maass form HkL which satisfies Examples harmonic Maass forms can constructed special values Maass Poincare series Let Following Section for and ZQh with MOCK MODULAR FORMS consider the Maass Poincare series Fhm A\\MpZ MsmvemuehkLA where Msv with the usual M-Whittaker function put Fhm Fhm qmeh which defines harmonic Maass form HkL that maps cusp form under Unary theta series and the eta function For consider the lattice can identify its discriminant form with ZNZ and slight abuse notation put CZNZ and write for the Weil representation associated with The unary theta function defined holomorphic modular form weight for For cusp form Familiar modular forms can expressed terms unary theta functions For example generalize this situation convenient phrase these identities terms eigenvectors the Weil representation Define Here write abe Lemma the notations above the vector resp generatesdimensional subspace invariant under resp which acts the space via resp Here MpZ the character MpZ defined Furthermore have Note that for the Maass Poincare series Fhm does not converge but can analytically continued via its Fourier expansion YINGKUN AND MARKUS SCHWAGENSCHEIDT Remark Note that the first two equations are equivalent and the third equation has been known Weber Remark For all the space Mrr Srrdimensional and spanned Proof Lemma The first claim can checked locally each prime The second claim follows from Remark and comparing Fourier coefficients Regularized inner product and pairing Let even lattice and satisfying sgnL mod Denote VkL hAL mZQh ahmqmeh ahm sgnL ahm for all vector space formal Laurent series with values CAL which contains the space weakly holomorphic modular forms Furthermore let denote the subspace consisting formal power series supported indices which contains the space MkL holomorphic modular forms the space VkL VkL define the bilinear pairing CTq hAL ghfh When restricted this pairing vanishes identically Furthermore and the holomorphic part harmonic Maass form weight for such that MkL application Stokes theorem gives see Proposition gGreg lim Gvkdudv where the usual fundamental domain for SLZ truncated the height clear that the pairing vanishes SkL Denote WkL VkL the subspace spanned and Serre duality compare Theorem know that SkL VkL WkL SkL VkL where the orthogonal complement taken with respect the pairing From this can deduce the following result MOCK MODULAR FORMS Lemma The pairing induces perfect pairing VkLM Proof Suppose VkL Then SkL WkL and can write with and That means and hence Again have SkL hence Proposition Let MkL and suppose that VkL satisfies gGreg for all Then mock modular form with shadow Proof The case follows directly from Lemma More generally can subtract from known mock modular form with shadow reduce the case Theta lifts this section compute some regularized theta lifts for lattices signature for The formulas this section are special cases the general results Borcherds and Bruinier but write down the simplifications for the convenience the reader Throughout this section let even lattice signature with and fix isotropic vector isotropic will choose primitive isotropic vector let GrL denote the Grassmannian positive lines For GrL consider the polynomials where write for the projection the subspace and For define the Siegel theta function GrL Note that for and every fixed GrL the polynomial harmonic and homogeneous degree Hence Theorem the theta function transforms like modular form weight for Moreover L-invariant The corresponding regularized theta lift weakly holomorphic modular form mmL defined lim dudv YINGKUN AND MARKUS SCHWAGENSCHEIDT Note that when resp will fix generators resp and remove the dependence and omit from the subscripts the general theory developed the theta lift converges for every GrL and real analytic singularities along the Heegner divisor where denotes the hypersurface consisting all GrL perpendicular These hypersurfaces partition GrL into infinitely many connected components the so-called Weyl chambers corresponding Theta lifts isotropic lattices signature Let isotropic even lattice signature with Let primitive isotropic and let with Choose some with some with and set Then has signature and see Proposition Let mod and let defined which induces surjection let Bkx denote the one-periodic function that agrees with the Bernoulli polynomial Bkx for Recall that the first few Bernoulli polynomials are given The theta lift has the following Fourier expansion MOCK MODULAR FORMS Proposition Let and let even lattice signature with primitive isotropic vector For mmL and every GrL have mzm QBmm afQp sgnpz sgn where the constant given mQm otherwise with for and Remark the same arguments the proof Theorem one can show that the sum the third line Proposition finite for every fixed GrL and vanishes for small enough Moreover the second line encompasses the singularities the theta lift along those with whereas the first line gives those with Remark For and the constant can also computed using Theorem writing linear combination the Maass Poincare series defined This yields the alternative representation Remark There mmL that allows rewrite Proposition for all mmL see for YINGKUN AND MARKUS SCHWAGENSCHEIDT Proof Proposition The formula follows from Theorem generalization Proposition where the Fourier expansion was computed fixed Weyl chamber GrL order extend the expansion all GrL one can use the shape the singularities the theta lift determine its wall crossing behavior point GrL moves across hypersurface the Heegner divisor from one Weyl chamber another compare also Corollary First Theorem for small enough the Fourier expansion the theta lift given the first three lines the expression the right-hand side the proposition The constant appearing Theorem vanishes and for equal the regularized integral lim fKK dudv where eQeK the holomorphic theta function associated the positive definite lattice particular the integral can viewed the regularized average value weakly holomorphic modular form weight for SLZ Hence can evaluated explained Remark Moreover Theorem generalization Theorem the theta lift has singularity type afQp sgnpz point GrL Here say that function has singularity type point there exists neighborhood such that and are defined and real analytic This definition slightly differs from the one used and but allows extend the Fourier expansion points GrL where the theta lift has singularities now easy check that the expression the right-hand side the proposition has the same singularities particular the difference and the expression the proposition defines real-analytic function all GrL and vanishes for small enough see also Remark and hence vanishes everywhere GrL This finishes the proof Theta lifts anisotropic lattices signature now compute the theta lift defined for anisotropic lattices signature One can compute the theta lift for anisotropic lattices signature for any similar Note that there sign missing the cited formula MOCK MODULAR FORMS way but the resulting formulas not look pleasing Hence confine ourselves with signature which suffices for our applications Another advantage that can fix generators and remove the isotropic vector from the notations Proposition Let but and let anisotropic lattice signature For any mmL and GrL have Qsgnpz msgnpz mpz pzm Remark For the proof below does not work since there might non-trivial holomorphic modular forms weight for cannot write linear combination Maass Poincare series and possibly invariant vectors Hence exclude this case from the above proposition Proof Proposition First note that cannot use Theorem since requires the existence isotropic vector Instead will write hAL afhmFhm linear combination the Maass Poincare series Fhm defined and L-invariant vector CAL Then compute the lift Fhm and using the unfolding argument the proof Theorem simplify the notation only treat the case here The other cases are analogous first show that the theta lift invariant vector CAL vanishes identically this end use the simple fact that every invariant vector can written linear combination residues Eisenstein series A\\MpZ vsehLA corresponding isotropic elements the usual unfolding argument one can show that multiple Lh\\ pzpz Qzs for large enough Since anisotropic the sum over with empty the theta lift vanishes identically for big enough particular YINGKUN AND MARKUS SCHWAGENSCHEIDT its residue vanishes well This shows that the theta lift invariant vector vanishes Hence suffices compute the lifts Poincare series Fhm Using the unfolding argument again find for big enough Fhm pzpz exp vQzQz The integral inverse Laplace transform see equation given Qzs Plugging and using that find Fhm pzpz Using and obtain the stated formula Note that contrast the isotropic case the sum the right-hand side Proposition not finite since the discriminant kernel infinite corresponds non-trivial subgroup the units real quadratic field However one can obtain finite evaluation the theta lift splitting the sum over modulo this end convenient view anisotropic lattices signature lattices real quadratic fields now explain Let non-square discriminant not necessarily fundamental let the corresponding real quadratic field and let its ring integers consider the subring given Notice that fundamental discriminant More generally with fundamental discriminant and then the order discriminant and conductor For integral ideal with and positive integer consider the lattice LaM QaM NmFQ MOCK MODULAR FORMS where denotes the norm The associated bilinear form BaM TrFQ where denotes the conjugate The lattice LaM anisotropic signature The dual lattice given adD where DOD the discriminant group LaM isomorphic ODMdD The discriminant kernel LaM generated and totally positive unit LaM which integral power the smallest totally positive unit For simplicity the following corollary already evaluate the theta lift certain special point which adjusted our later applications view LaM QaM sublattice sending LaM will choose the generators and with and Corollary Suppose that LaM QaM anisotropic lattice the form Let mmL and let GrL the positive line generated Then have afQsgnTrFQ DAM QsgnTrFQ DAM QsgnTrFQ where and The sums the right-hand sides are finite Proof Again only treat the case for simplicity First note that have Using Proposition find afQsgn afQsgn min where used that minx for with and sgn sgn since Let the subgroup consisting totally positive units Note that the terms with contribute nothing system YINGKUN AND MARKUS SCHWAGENSCHEIDT representatives for choose the set Then the set all with and given For and have minnL sgnnL obtain afQsgn min This yields the stated formula The sums the right-hand side the corollary are finite since has finite principal part and the intersection resp with the set vectors fixed norm finite Proof Theorem consider the even lattice signature and level the four-square theorem can find primitive isotropic vector Then have for some satisfying Let and such that and Denote order show that the mock modular forms are going construct below have bounded denominators will need bound the denominators vectors Namely claim that Indeed for any the first coordinate and has level Using the surjection can find such that Since have claimed Now come the construction mock modular form whose shadow given this end will first compute the regularized Petersson inner product reg for every using the theta lift studied Section Then can express this inner product terms the pairing for some explicit Laurent series and finally apply Proposition obtain the desired mock modularity MOCK MODULAR FORMS easy check that the theta function defined splits the line generated tensor product Then for each have reg reg where with defined From Proposition see that reg with the power series chmq defined chm Kph sgnpw sgn where understand that the first sum vanishes Note that for the above discussion and since has level Recall that the one-periodic function that agrees with for This implies that has coefficients write then the Laurent series vFw has coefficients and satisfies reg for any Hence Proposition implies that mock modular form weight with shadow Moreover has integral coefficients This finishes the proof the first item Theorem YINGKUN AND MARKUS SCHWAGENSCHEIDT The proof the second item Theorem analogous now using the theta lift with constant polynomial particular using Proposition and the arguments above can construct mock modular form whose coefficients have denominators which are bounded the other hand use the alternative expression for the constant can construct mock modular form with rational coefficients whose denominators are bounded Combining these two mock modular forms using the trick from Remark can bound the denominators gcdN Remark the sum two squares then can carry out the argument above with and the factor can reduced mod then the factor can reduced combining with Proposition and Remarks Proof Theorem and Example For any integral OD-ideal co-prime denote LaM anisotropic lattice signature defined Since the eigenform linear combination components the vector-valued cusp form R\\R sgnqQe suffices consider itspreimage This constructed log where deformed theta integral and real-analytic modular form weight one satisfying Here denotes the theta function which evaluate the point the proof Theorem loc cit the number defined bound the denominator Fourier coefficients the holomorphic part For this purpose enough produce suitable having rational Fourier coefficients with good denominator bound this consider the lattice and obtain Applying Proposition again gives for any reg The holomorphic function also called mixed mock modular form the sense MOCK MODULAR FORMS where and hARA Fwheh defined the same way with any primitive isotropic vector co-prime can find such that gcdD taking can conduct the same analysis the proof Theorem see that DMFw has integral coefficients slight variant Proposition then implies that hAR vFwh the holomorphic part weight real-analytic modular form satisfying This gives the bound which leads the improvement following the same proofs Theorems and This finishes the proof Theorem For Example take and Then and Furthermore have QAQA QAR Let above and its modular completion Then qQJqK and theimage its modular completion From and Remark then know that the trivial space with the character defined Finally Proposition shows that the holomorphic part given aOF Nma qRJqK Therefore defined the holomorphic part the harmonic Maass form log whoseimage Explicit constructions mock modular forms this section compute explicit mock modular forms weight and using the evaluations theta lifts for lattices signature given Section Mock modular forms weight construct mock modular forms weight for with shadow for every YINGKUN AND MARKUS SCHWAGENSCHEIDT Proposition Suppose that square Then xyZ sgnxyq mock modular form weight for with shadow Here the one-periodic function that agrees with the Bernoulli polynomial for and the holomorphic quasimodular Eisenstein series weight Suppose that not square Let and let the smallest totally positive unit such that even and lcmN Then xyZ sgnxTrFQ mock modular form weight for with shadow Proof The proof similar the proof Theorem but will give some details for the convenience the reader Let first assume that square Then the lattice has signature and isotropic Its dual lattice given choose the primitive isotropic vector Then have The theta function considered Section splits the special point tensor product Hence using Lemma can write for any reg reg MOCK MODULAR FORMS where the other hand Proposition implies that the theta lift can expressed terms the pairing defined with the power series sgnpw sgn qQeL Here used that the lattice trivial and that system representatives for given where runs modulo particular follows from Proposition that the Laurent series mock modular form weight with shadow Using and for easy obtain the representation given the proposition leave the details the simplification the reader The proof for not being square similar will only give sketch this case use certain lattice LaM the shape let even and odd choose even odd even odd Note that the first case have and the second case have any case have LaM QaM NmFQ can now proceed similarly the case being square now using the evaluation the theta lift given Corollary easy see that the unit LaM characterized the conditions given the proposition YINGKUN AND MARKUS SCHWAGENSCHEIDT Remark For being square the authors constructed the mock modular form xyZ sgnx weight with shadow The difference with the mock modular form constructed Proposition given times Eisenstein series weight for which can for example constructed integral Kudla-Millson theta function Theorem For fixed the number with and finite Indeed the above conditions imply that satisfy the inequalities sgnyx particular the coefficient the inner sum item Proposition given finite sum rational numbers square then the denominators the coefficients are bounded not square then can write TrFQ TrFQ NmFQ TrFQ TrFQ which implies that the denominators the coefficients are bounded TrFQ the numerical examples that looked the denominators the coefficients were usually bigger than the bound from Theorem Example Consider Ramanujans classical mock theta functions order qnn MOCK MODULAR FORMS The fundamental work Zwegers see also Section shows that the CZZvalued function fqe the holomorphic part harmonic Maass form weight for the dual Weil representation associated with comparing principal parts obtain that where the mock modular form constructed the second item Proposition above and the Atkin-Lehner involution that interchanges with with with and fixes all other elements For example this implies the identity xyZ sgnxTrFQ where and square then can use the theta lift the isotropic lattice and apply similar arguments the proof Proposition obtain the following formula Proposition Suppose that square Then xyZ sgnxq mock modular form weight for with shadow Here the one-periodic function that agrees with the Bernoulli polynomial for Example Arguing Example obtain from Proposition the identity xyZ sgnxq YINGKUN AND MARKUS SCHWAGENSCHEIDT for Ramanujans order mock theta function This identity very similar the ones for Ramanujans mock theta functions order and given Section Remark Unfortunately not square our method does not work before this case would need evaluate the theta lift anisotropic lattice signature where weight weakly holomorphic modular form for Since there might holomorphic modular forms weight for cannot write linear combination Maass Poincare series compute the theta lift the unfolding argument Proposition wonder our method can adjusted obtain mock modular form with shadow using the theta lift for anisotropic Mock modular forms weight now give explicit mock modular forms weight with shadow The construction works analogously the proof Proposition omit the details for brevity Using the signature theta lift with constant polynomial considered Section obtain the following mock modular forms Proposition Suppose that square Then xyZ mock modular form weight for with shadow Here the one-periodic function that agrees with the Bernoulli polynomial for and the holomorphic quasimodular Eisenstein series weight Suppose that not square Let and let the smallest totally positive unit such that even and lcmN Then xyZ sgnyTrFQ mock modular form weight for with shadow Similarly using the signature theta lift with degree polynomial obtain the following result MOCK MODULAR FORMS Proposition Suppose that square Then xyZ xyq mock modular form weight for with shadow Here the one-periodic function that agrees with the Bernoulli polynomial for Suppose that not square Let and let the smallest totally positive unit such that even and lcmN Then xyZ sgnyTrFQ mock modular form weight for with shadow References Borcherds Automorphic forms with singularities Grassmannians Invent Math Borcherds The Gross-Kohnen-Zagier theorem higher dimensions Duke Math Borcherds Correction The Gross-Kohnen-Zagier theorem higher dimensions Duke Math Duke Math Bringmann Folsom and Ono q-series and weight Maass forms Compos Math Bringmann and Ono Dysons ranks and Maass forms Ann Math Bruinier Borcherds products and Chern classes Heegner divisors Number Lecture Notes Mathematics Springer-Verlag Berlin Bruinier Ehlen and Yang values higher automorphic Green functions for orthogonal groups preprint arXiv Bruinier and Funke two geometric theta lifts Duke Math Bruinier and Funke Traces values modular functions Reine Angew Math Bruinier and Ono Heegner divisors L-functions and harmonic weak Maass forms Ann Math Bruinier and Schwagenscheidt Algebraic formulas for the coefficients mock theta functions and Weyl vectors Borcherds products Algebra YINGKUN AND MARKUS SCHWAGENSCHEIDT Bruinier and Schwagenscheidt Theta lifts for Lorentzian lattices and coefficients mock theta functions Math Zeit Charollois and Harmonic Maass forms associated real quadratic fields Eur Math Soc JEMS Dabholkar Murthy and Zagier Quantum black holes wall crossing and mock modular forms Cambridge Monographs Mathematical Physics appear pages Ehlen values regularized theta lifts and harmonic weak Maass forms weight Duke Math Erdelyi Magnus Oberhettinger and Tricomi Tables integral transforms Vol McGrawHill Book Company Inc New YorkToronto-London Based part notes left Harry Bateman Funke and Millson Spectacle cycles with coefficients and modular forms half-integral weight Arithmetic Geometry and Automorphic Forms honor Stephen Kudla Higher Eduction Press and International Press Hecke Zur Theorie der elliptischen Modulfunktionen Math Ann Hirzebruch and Zagier Intersection numbers curves Hilbert modular surfaces and modular forms Nebentypus Invent Math Average CM-values higher Greens function and factorization preprint arXiv Viazovska Petersson inner products weight-one modular forms Reine Angew Math Zagier Nombres classes formes modulaires poids Acad Sci Paris Zagier Ramanujans mock theta functions and their applications after Zwegers and OnoBringmann Number pages Exp viiviii Seminaire Bourbaki Vol Zwegers Mockfunctions and real analytic modular forms Contemp Math ZwegersMock Theta Functions Proefschrift Universiteit Utrecht Thesis PhDUniversiteit Utrecht Fachbereich Mathematik Technische Universitat Darmstadt Schlossgartenstrasse Darmstadt Germany Email address li@mathematik.tu-darmstadt.de ETH Zurich Mathematics Dept Ramistrasse CHZurich Switzerland Email address mschwagen@ethz.ch Introduction Preliminaries Modular forms for the Weil representation Unary theta series and the eta function Regularized inner product and pairing Theta lifts Theta lifts isotropic lattices signature Theta lifts anisotropic lattices signature Proof Theorem Proof Theorem and Example Explicit constructions mock modular forms Mock modular forms weight Mock modular forms weight References"
" Does Continual Learning Catastrophic Forgetting? Anh Thai Stefan Stojanov Zixuan Huang Isaac Rehg James Rehg Georgia Institute Technology {athai6,sstojanov,zixuanh,isaacrehg,rehg}@gatech.edu Abstract Continual learning known for suffering from catastrophic forgetting phenomenon where earlier learned concepts are forgotten the expense more recent samples this work challenge the assumption that continual learning inevitably associated with catastrophic forgetting presenting set tasks that surprisingly not suffer from catastrophic forgetting when learned continually provide evidence that these reconstructiontype tasks exhibit positive forward transfer and that singleview shape reconstruction improves the performance learned and novel categories over time provide the novel analysis knowledge transfer ability looking the output distribution shift across sequential learning tasks Finally show that the robustness these tasks leads the potential having proxy representation learning task for continual classification The codebase dataset and pre-trained models released with this article can found https://github.com/rehg-lab/CLRec. Introduction continual learning stream incrementallyarriving inputs processed without access past data key challenge avoid catastrophic forgetting large negative backward transfer BWT which arises previously-learned representations are degraded more recent exposures Substantial effort has been made combat forgetting and has come exemplify continual learning However past works have explored surprisingly limited set tasks with almost exclusive focus classification this work demonstrate the surprising finding that broad set continual reconstruction tasks including shape reconstruction sketch estimation and image reconstruction not exhibit catastrophic forgetting Sec fact show that these tasks exhibit minimal negative backward transfer and even positive backward transfer without the use any heuristics strategies prevent forgetting the best our knowledge are the first provide extensive study for reconstructiontype tasks Our findings suggest that the challenge catastrophic forgetting established prior work classification does not fact characterize all problems addition mitigating negative BWT another essential characteristic successful models achieving positive forward transfer FWT Positive FWT arises when models representation trained sequence prior tasks beneficial for future learning task This important property because can enable methods leverage shared representations common property batch learning methods learning low-level visual features image classification and goal transfer learning Collectively BWT and FWT characterize the effectiveness methods evolving feature representations incrementally Recently the GDumb classifier baseline has called the role FWT into question GDumb episodic representation learner which maintains set evolving exemplar memory but reinitializes the feature representation and trains from scratch during each learning exposure eliminating the possibility FWT GDumb was shown out-perform other state-of-the-art methods which were designed achieve positive FWT highlighting the tension between the goals achieving positive FWT and avoiding negative BWT These prior findings for classification beg the question whether achieving positive FWT beneficial for reconstruction demonstrate that continuously-updated representations lead improved performance and positive FWT for variety reconstruction tasks see Sec limitation prior work knowledge transfer FWT and BWT that the findings depend upon the use specific method basic question whether can find algorithm-agnostic characterizations tasks that might shed light the surprising behavior continual reconstruction define measure the output distribution shift across learning exposures and demonstrate that small distribution shifts across sequential tasks lead better knowledge transfer and improvements BWT and FWT use the term learning exposure refer each new increment data the learners next exposure the concepts being learned Input Rep Output Rep Reconstruction Tasks Image auto-encoding Fig Single-view Silhouette Pred Fig Single-view Depth Pred Fig Single-view Surface Normals Pred Fig Single-view Image Shape Rec Figs Single-view Depth Shape Rec Figs Single-object Pointcloud Shape Rec Fig Table Summary the reconstruction tasks evaluate that demonstrate robustness catastrophic forgetting There are types tasks based the input output representation mapping Sec This gives the ability forecast the performance supervised task way that agnostic the algorithm and backbone architecture design believe these are the first results demonstrate the feasibility approximating the difficulty task without performing computationally expensive model training means further investigate the relationship between continual reconstruction and categorization demonstrate that continual single-view shape reconstruction can serve effective proxy task for classification Specifically continuously-trained shape representation without any class label supervision effective for continual image classification given only small exemplar budget Sec summary this paper makes the following contributions The novel finding that some continual reconstruction tasks Tbl not suffer from catastrophic forgetting Sec That these continual reconstruction tasks demonstrate positive forward transfer and the ability single-view shape reconstruction generalize novel classes unseen during training Sec Novel analysis knowledge transfer ability demonstrates that smaller output distribution shift across learning exposures leads better knowledge transfer Sec Using single-view shape reconstruction proxy task for classification results competitive method given limited exemplar budget Sec Related Work Our work most closely-related four bodies prior work works outside the image classification paradigm relevant our findings for reconstruction Analysis relevant our output distribution shift analysis Generalization ability models for single image shape reconstruction relevant our investigation generalization ability single-view shape reconstruction models and for classification task relevant our proxy representation task findings Non-Classification Tasks are the first investigate and demonstrate that set tasks intrinsically robust catastrophic forgetting While most prior works have addressed image classification few prior works have addressed various other tasks Aljundi studied the problem actor face tracking video while explored image segmentation Shmelkov and Liu investigated incremental object detection while learned image generation Elhoseiny examined continual fact learning utilizing visual-semantic embedding Wang studied camera localization given input RGB image while Cai explored online geolocalization with natural distribution shift the input that occurs over real time Others focused reinforcement learning task Most closely related our work Yan that investigated continual learning scene reconstruction Similar our work they employed implicit shape representation signed-distance-field represent scenes contrast this work aimed continually reconstruct the input scene given stream depth images from different views The input distribution shift this setting the shift between one view the scene another and the objective produce smooth representation the same input scene observed over time Our work the other hand explores reconstruction task the context visual classes which more challenging since the underlying semantic the inputs changes over time Note that all these works reported challenges with catastrophic forgetting commensurate with the classification setting Analysis Continual Learning Our analysis the behavior tasks most closely related the body works that analyzes general dynamics While Verwimp examined the benefits and drawbacks rehearsal methods Knoblauch showed that optimal algorithms solve NP-HARD problem and require perfect memory Specifically optimal parameters for each new task must lie the intersection SAT all tasks learned Perfect memory refers the ability approximate the parameters that optimize all seen tasks This approach explains the merit employing memory replay instead regularization-based approaches While discussed the different concept drift our analysis focuses more the output distribution shift that can used means understand the knowledge transfer ability various tasks Generalization Batch-Mode Shape Reconstruction Our analysis the generalization ability single-view shape reconstruction task Sec based prior works that investigate the ability single image shape reconstruction models generalize unseen shape categories batch mode are the first provide generalization analysis these models the setting utilizing theDOF approach which has been Figure Performance shape reconstruction methods with and inputs when presented with single exposure for each category from all categories ShapeNetCorev classesexposure repeated exposures case ShapeNet with repeated exposures classesexposure single exposure case ShapeNetCorev shape methods with inputs Backward transfer reported parenthesis Catastrophic forgetting does not happen any the algorithms any case shown learn more general shape representation than the object-centered approach for Classification Our work reconstruction-based proxy task for classification Sec unique but peripherally-related other works which explore alternative classification losses forms supervision share with the use the nearest-class-mean NCM classification rule use NCM for classification based latent shape representation trained without class supervision while use NCM for classification embedding layer which trained with ground-truth class labels Another related work Rao performs unsupervised multi-task setting where the boundaries between tasks are unknown contrast our unsupervised training paradigm utilizes single-view shape reconstruction proxy task Problem Formulation Supervised Reconstruction Tasks The objective these tasks learn the mapping function over the observed the data For example single-view shape reconstruction aims output the shape the object represented the input image while depth map reconstruction predicts the depth values the sceneobject given the input Note that and can different depending the specific reconstruction task considered Generally the desired function composition two functions The encoder extracts the feature representation from the input followed the decoderD that produces the output from the encoded feature representation Continual Learning Reconstruction this setting each learning exposure the learning model observes the data xti indexed and learns optimize the parameters the function minimizing the supervised loss EDt ftx where some loss function associated with the specific reconstruction task employ the notion single exposure refer the standard continual learning paradigm where data introduced sequentially and never revisited while repeated exposures refers the paradigm introduced Stojanov where data can revisited after being learned this setting each visual class occurs fixed number times repetitions random order Note that this work assume that each defined over set ofMt visual categories Training During training the learning model does not have access previously seen dataDt optimize the parameters the function continuously each learning exposure upon observing the data stream Specifically the learned parameters exposure serve the initialization parameters for the model exposure which referred continuous representation learning This the standard SGD training that has been shown suffer from catastrophic forgetting prior works Without any further heuristics such additional losses external memory other methods employed this technique referred finetuning strategy Evaluation test time the model evaluated the test split all known categories Specifically each learning exposure compute the average accuracy all classes seen Specifically Acct acc where the number classes seen exposure and acc the accuracy class after learning exposure Plotting the average accuracy all learning exposures results the learning curve the model Fig Note that accuracy metrics reported for all the tasks are range further report backward and forward transfer metrics addition the average performance curve each learning exposure Specifically backward transfer BWT measures the average change performance the last learning exposure wrt when the concepts are first introduced and forward transfer FWT indicates the average change performance between the random initialization and the performance the learning exposure right before the concepts are introduced Note that while BWT bounded FWT depends the random initialization performance each dataset more successful learner will demonstrate higher BWT and FWT Positioning Reconstruction Considering the three continual learning scenarios reconstruction most Details discussed the Supplement Organizing shapes into categories allows characterize how new shape concepts are introduced during learning Figure Results for estimation Performance terms thresholding accuracy for depth prediction and thresholding cosine distance for surface normals IoU silhouette prediction model SSIM image autoencoding Backward transfer reported parenthesis The performance models increases over time and approaches batch reconstruction task closely related Domain-IL scenario both settings the learning objective depth value prediction the same across learning exposures but the input data distribution changes over time from one set visual classes another This breaks the iid-sampling assumption present the SGD optimization procedure where each training minibatch sampled iid from the entire data distribution This presents the same main challenges faced other tasks such classification object detection and segmentation Reconstruction Tasks Not Suffer from Catastrophic Forgetting identify types reconstruction tasks based their input and output properties listed Tbl Our key finding that tasks each these five types not suffer from catastrophic forgetting important emphasize that the continual learning algorithm used this section the simple finetuning strategy specified Sec that known perform poorly for classification task Specifically not need utilize additional losses external memory other methods achieve good continual learning performance Note that different categories shapes exhibit significant domain shift that poses significant challenges continual learning For example the categories chair and bowl ShapeNet define very different data distributions with parts common From this point view quite surprising that not observe forgetting for such continual reconstruction tasks therefore organize shapes category constructing our learning exposures that the category label means characterize the domain shift between successive exposures Our findings for learning shape reconstruction prediction and reconstruction are presented Secs and respectively report the average accuracy each learning exposure described Sec and backward transfer for all the experiments Single Object Shape Reconstruction first present reconstruction tasks where the output representation Specifically the goal the desired function produce surface representation the single object present the input examine implicit continuous representations such signed-distance-fields SDF and continuous occupancies since they were identified achieve superior performance the batch setting Approach utilize SDFNet and OccNet backbone architectures for train both methods with theDOF representation varying azimuth elevation and camera tilt from which was shown give the best generalization performance also train with representation for SDF representation which the model trained output the shape the canonical pose examine the behavior these models given different input representations where inputs are single-view RGB images where inputs are ground truth depth and normals maps and where inputs are sparse pointclouds Datasets Metric train all classes ShapeNetCorev instances with classes per exposure for the single exposure case and the largest classes ShapeNetCorev meshes denoted ShapeNet with classes per exposure for the repeated exposure case Note that ShapeNetCorev currently the largest shape dataset with category labels and ShapeNet the standard split for shape reconstruction Each exposure generated from all the samples from the training split each category currently present Following prior works shape reconstruction report the average FS@1 each learning exposure use SDFNet the batch reference All models are trained from random initialization Results The results are shown Figs and for single and repeated exposures all single object shape reconstruction settings last rows Tbl For single exposure with and inputs Fig all algorithms maintain their accuracy over time and even exhibit slight upward trend increasing accuracy while for inputs Fig the performance significantly increases over time and par with batch Note that conducted runs and the results converge the same conclusion with average std each learning exposure All models including the model trained with representation not suffer from catastrophic forgetting evidenced the minimal negaSDFNet withDOF the current SOTA for single image shape reconstruction provide more details our dataset use and licensing Supp For instance chair and table are present the current learning exposure the model will trained all chairs and tables the respective training splits tive and even positive backward transfer This surprising since are not taking any steps ameliorate catastrophic forgetting and each learning exposure presents significant domain shift the learner must incorporate information about the shape new class objects Since SDFNet and OccNet differ significantly shape representation and are trained with different losses loss for SDFNet and BCE loss for OccNet this finding possibly reflects basic property the shape reconstruction problem rather than the inductive biases particular model the repeated exposures setting Fig the performance both architectures when trained withDOF improves significantly over time and eventually performs par with the batch learner These models achieve significant positive BWT which indicates that catastrophic forgetting mitigated Unlike the experiments which showed similar asymptotic behavior for classification accuracy these results were obtained without exemplar memory other heuristics Note that SDFNet trained with does not show significant increaseDOF over time This complements the finding that training with DOF results more robust feature representation Single-view Sketches Prediction The task Sec requires the model infer the global structure each object this section investigate the related task estimating depth and surface normals from RGB input images the single exposure case Tbl second row adopt the U-ResNet-based MarrNet architecture with ILSVRCpretrained ResNet for the image encoder evaluate depth prediction using the commonly used thresholding accuracy For normals prediction report the accuracy based the cosine distance threshold between the predicted and ground truth surface normals Fig demonstrates that single exposure prediction does not suffer catastrophic forgetting the accuracy increases over time These findings further extend the shape reconstruction results from Fig Reconstruction The tasks Secs and require the model solve challenging inference problem conduct additional experiments continual mapping that includes learning segment foregroundbackground given RGB input image and image autoencoding For silhouette prediction utilize U-ResNet-based MarrNet architecture train with BCE loss report the average IoU each learning exposure Fig which demonstrates that single exposure silhouette prediction does not suffer The learning exposures axis Fig result from ShapeNet classes divided classes per exposure with repetitions each More details Supplement catastrophic forgetting minimal negative backward transfer fact observe that the IoU increases over time For image autoencoding present results Fig use randomly initialized shallow architecture with conv layers followed max pooling for the encoder where the bottle-neck feature vector has dimension experiment CIFARsize with one class per exposure and use SSIM scaled range the accuracy metric SSIM increases over time and eventually reaches batch performance This yet more evidence for the robustness continual reconstruction Discussion Reconstruction Limitations have identified for the first time set continual reconstruction tasks that not suffer from forgetting evidenced the results Figs and These models were trained with standard SGD without exemplar memory other heuristics One point contact between classification and reconstruction that both sets tasks benefit significantly from repeated exposures see Fig Sec demonstrate the value continuously-updated representations both seen and novel classes now briefly discuss two potential limitations our work First our reconstruction experiments with the exception image autoencoding all use synthetic object models opposed real-world images However point out that shape reconstruction synthetic images with and inputs still very challenging computational problem the SOTA result ShapeNet FS@1 out maximum This turn raises the second possible limitation that the lack forgetting may tied part the fact that the models are not yet able achieve very high accuracy More accurate models might more closely tuned the data distribution each exposure increasing the potential for domain shift While this might true for shape reconstruction from and inputs the shape reconstruction from inputs and reconstruction tasks achieve high level accuracy which provides counterpoint the argument Sec provide one explanation for these observations hope this work will encourage the community conduct additional investigations into this intriguing phenomenon Negative societal impacts Training models computationally expensive since the models are trained convergence for multiple learning exposures This can mitigated algorithm improvements that allow models learn faster Keeping exemplar memory for replay might violate the privacy policies for sensitive data which can addressed generative methods Figure Performance seen classes GDumb and GSmart shape reconstruction with inputs ShapeNet with exemplars training data GSmart outperforms GDumb significant margin Generalization performance unseen categories ShapeNetCorev GDumb GSmart and C-SDFNet Generalization ability GSmart and C-SDFNet increases over time while constantly staying low for GDumb demonstrates the benefit continuous representation learning Note that all models are trained withDOF approach Forward Transfer Single-view Reconstruction this section discuss the ability the learning model propagate useful representations learned the past current and future learning exposures positive FWT focus our analysis the challenging problem single-view shape reconstruction first demonstrate that continuous representation learning beneficial observe significantly stronger performance compared episodic representation learning for this task further note that positive FWT obtained evidenced the accuracy improvement seen and novel classes over time While generalization unseen classes has been studied extensively the batch setting single-view shape reconstruction and has been identified significantly challenging problem are the first analyze this behavior continual learning setting GDumb episodic representation learner designed test the hypothesis that there value continuous representation learning Specifically each learning exposure the model randomly reinitialized and trained from scratch the exemplar set which ensures that subset data from all previous learning exposures available This approach surprisingly achieves competitive performance classification hypothesize that contrast this observation continuous representation learning improves the performance single-view shape reconstruction due the feasibility positive FWT order test this hypothesis design GSmart algorithm that continuously trains the feature representation instead reinitializing the weights each learning exposure GDumb See the supplement for details Note that both methods are trained the same sized exemplar set randomly selected each learning exposure conduct our experiments ShapeNet with single exposure and shape class per learning exposure choose total training data the exemplar set size and evaluate the performance the models all learned classes Sec Fig observe that the performance GSmart improves over time and eventually exceeds that GDumb FS@1. This significant gap highlights the benefit continuous representation learning across each learning exposure further investigate the ability these models generalize novel categories evaluate GDumb GSmart and continual SDFNet C-SDFNet Sec held out set classes ShapeNetCorev with instances for each category Fig All algorithms perform poorly the unseen classes after the initial learning exposures which demonstrates that significantly challenging generalize novel categories after learning only few classes However the performance C-SDFNet and GSmart improves over time more classes are learned while GDumb remains low This illustrates benefit continuous representation learning useful feature that aids generalization and improves the performance novel classes over time note that positive FWT also observed other reconstruction tasks see Tbl Analysis Knowledge Transfer Ability Our findings Secs and have highlighted the significance knowledge transfer reconstruction While BWT and FWT quantify the knowledge transfer during they require training and evaluating computationally expensive models Furthermore these measures only reflect the performance specific algorithms and not speak task general this section attempt gain more insight into knowledge transfer given task and dataset algorithm-agnostic manner focusing changes the output distribution use this approach further analyze the benefit exemplar memory classification begin stating key hypothesis connecting the output distribution task knowledge transfer ability Hypothesis Given supervised task with input and output distributions and each learning exposure the Training and evaluating shape reconstruction from inputs ShapeNetCorev takes days two NVIDIA GeForce RTX GPUs the other hand computing output distribution distance only takes minutes which two orders magnitude more efficient Task Mean Dist BWT FWT Sil Pred Shape Rec Depth Pred Shape Rec Classification Table The relationship between the mean output distribution distance across learning exposures and BWT and FWT for different tasks Lower better for distribution distance while higher better for BWT and FWT Lower distance leads better knowledge transfer higher BWT and FWT model observes and hypothesize that the distance the conditional distribution YtXt between each learning exposure becomes smaller knowledge backward and forward transfer increases for any method now present the intuition behind our formulation Let some dataset consisting two parts and that are independently generated During batch training optimize the parameters minimizing the loss argmin log Since and and are independent becomes argmin log log log pYX log pYX During continual learning when and are learned sequentially optimize log and log separately which leads suboptimal solution for When the distance between the conditional distributions and small more likely that the optimal parameters for coincides with the optimal parameters for and hence the joint parameters that optimize the batch training model Analysis this section demonstrate the empirical evidence for the earlier hypothesis Note that all the following analyses the inputXt defined visual object category Distribution Distance Metric use the first Wasserstein distance metric EMD quantify the distance between two output distributions EMD was introduced Rubner measure the structural similarity between distributions contrast other statistical measurements like divergence Chi-squared statistics EMD can used measure the similarity between both continuous and discrete distributions with different supports Given distributions and define inf ydx and express the distance between two learning exposures and dut utds Output Distribution Distance BWT Num Exemplars sAnalysis Output Distribution Shift CIFARFigure The relationship between the output distribution shift across learning exposures the number exemplars per class and BWT CIFARExperiments are run for exemplarsclass Larger exemplar set size leads smaller output distribution distance and higher BWT where and are the output distributions exposures and respectively and the support set and now analyze the output distribution shift for different continual learning tasks Shape Reconstruction this setting the output SDFt represents the ground truth SDF values for the support set consisting coordinates first select points uniformly unit grid resolution For each shape class randomly sample objects Each point defines distribution SDF values within shape class tqi SDFt From the final output distribution distance between each shape class where the number points present the results for both coordinate representations andDOF described Sec Depth Prediction and Silhouette Prediction this setting pixt represents the value each pixel the input depth value and binary value for depth and sihouette pred respectively The support set the set pixel coordinates Each pixel then defines distribution pixel values within class tpi pix The output distribution distance between each class where the number pixels For depth prediction first center crop the input images For each class randomly sample objects and for each image sample pixels uniformly Classification The output represents the ground truth class labels the inputXt The output distribution for each class then PYt cXt Different from the reconstruction tasks the output distribution between each learning exposure does not share support set assume that the class labels are sequentially incremented integers for each new class the sequence The final output distribution distance computed Small output distribution shift associated with improved knowledge transfer first compute the output Learning Exposures Classification Performance ShapeNet with Single Exposure Proxy Rep Learning ImageNet Pretrained Classifier Exemplr GDumb Batch Figure Performance proxy representation learning task Proxy Rep Learning continual learning classification ShapeNet with RGB input Given limited exemplar budget shape reconstruction proxy representation learning outperforms ImageNet pretrained features and classification baselines distribution distance described above for each task and compare with the resulting BWT and FWT verify the effectiveness the proposed method and ensure fairness continually train each task using the finetuning strategy ShapeNet from RGB input images with class per learning exposure and report the average output distribution distance and the BWT and FWT metrics Tbl shows that our hypothesis holds the small output distribution distance associated with higher BWT and FWT can also seen that classification has significantly larger output distribution distance compared reconstruction tasks and exhibits significantly reduced FWT and BWT Effect exemplar set size output distribution shift apply this analysis technique gain insight into the effectiveness replay methods commonly used avoid catastrophic forgetting classification design our experiment CIFARwith class per learning exposure employ randomly initialized ResNet and vary the exemplar set size from exemplarsclass Fig illustrates that larger exemplar set size associates with smaller conditional output distribution shift which results improvement BWT Proxy Task for Continual Classification The robustness representation learning and the ability transfer knowledge between learning exposures single-view shape reconstruction begs the question whether could used proxy task improve classclassification test that hypothesis here via simple approach train reconstruction model SDFNet RGB images continually Sec and inference time extract the feature from its image encoder with forward pass maintain exemplar set imagesclass with class labels randomly sampled from the training dataset not use the labels for training Instead use the extracted representation nearestclass-mean NCM classification with the exemplars testing time Specifically the mean feature each class first computed from the exemplar set Then test samples are asthis setting the learning model required discriminate all learned classes signed the label the closest mean feature via cosine distance decide utilize NCM classifier instead training fully-connected layer with cross-entropy loss due the fact that the exemplar set size small the training data and has been shown that linear classifier trained with loss tends overfit significantly when the dataset imbalanced conduct experiments with ShapeNet with one class per exposure first show that the feature representation learned the single-view shape reconstruction task discriminative despite not having access ground truth labels during training compare the performance the proxy classifier against ImageNet pretrained feature representation model Specifically extract the feature from the ImageNet pretrained ResNet via forward pass and use NCM the classifier with the same exemplar set size the proxy classifier Fig shows evidence that shape features are more beneficial for continual classification than the rich discriminative feature representation from ImageNet further compare the proxy classifier against two classification baselines GDumb and standard classifier trained continually with cross entropy loss and the same exemplar set denoted Classifier with Exemplars Fig shows that the shape proxy classifier outperforms the GDumb and Classifier with Exemplars ShapeNet This demonstrates that significant amount discriminative information encoded the continual shape representation and suggests that may beneficial explore other proxy tasks means improve classification Conclusion have identified set reconstruction tasks including shape reconstruction sketch estimation and image reconstruction that not exhibit catastrophic forgetting Hence the answer the question pose our title Does continual learning catastrophic forgetting? general despite the central role forgetting prior research continual classification further show that reconstruction tasks benefit from continuous representation training and exhibit positive forward transfer addition the continual version the challenging singleview shape reconstruction task demonstrates improvements performance over time both seen and novel categories are the first investigate the generalization ability single-view shape reconstruction models the context provide novel algorithm-agnostic means characterize the knowledge transfer performance tasks via output distribution shift analysis show that reduction shift associated with increased knowledge transfer link reconstruction and classification showing that feature representations from reconstruction can effective for classification under limited exemplar budget Our findings point need enlarge the space tasks and develop algorithm-agnostic measures performance Acknowledgement would like thank Miao Liu and Meera Hahn for the helpful discussion This work was supported NIH R-MH and NSF Award This paper dedicated the memory Chengming Julian References Plop Learning without forgetting for continual semantic segmentation Proceedings the IEEE Conference Computer Vision and Pattern Recognition CVPR David Abel Dilip Arumugam Lucas Lehnert and Michael Littman State abstractions for lifelong reinforcement learning International Conference Machine Learning pages Rahaf Aljundi Klaas Kelchtermans and Tinne Tuytelaars Task-free continual learning Proceedings the IEEECVF Conference Computer Vision and Pattern Recognition CVPR June Blender Online Community Blender modelling and rendering package Blender Foundation Blender Institute Amsterdam Zhipeng Cai Ozan Sener and Vladlen Koltun Online continual learning with natural distribution shifts empirical study with visual data Proceedings the IEEECVF International Conference Computer Vision ICCV pages October Francisco Castro Manuel Marin-Jimenez Nicolas Guil Cordelia Schmid and Karteek Alahari End-to-end incremental learning Proceedings the European Conference Computer Vision ECCV pages Fabio Cermelli Massimiliano Mancini Samuel Rota Bulo Elisa Ricci and Barbara Caputo Modeling the background for incremental learning semantic segmentation Proceedings the IEEECVF Conference Computer Vision and Pattern Recognition CVPR June Angel Chang Thomas Funkhouser Leonidas Guibas Pat Hanrahan Qixing Huang Zimo Silvio Savarese Manolis Savva Shuran Song Hao Shapenet informationrich model repository arXiv preprint arXiv Christopher Choy Danfei JunYoung Gwak Kevin Chen and Silvio Savarese d-rn unified approach for single and multi-view object reconstruction European conference computer vision pages Springer Matthias Lange Rahaf Aljundi Marc Masana Sarah Parisot Jia Ales Leonardis Gregory Slabaugh and Tinne Tuytelaars continual learning survey Defying forgetting classification tasks arXiv preprint arXiv Mohamed Elhoseiny Francesca Babiloni Rahaf Aljundi Marcus Rohrbach Manohar Paluri and Tinne Tuytelaars Exploring the challenges towards lifelong fact learning Asian Conference Computer Vision pages Springer Xisen Jin Junyi and Xiang Ren Gradient based memory editing for task-free continual learning arXiv preprint arXiv Christos Kaplanis Murray Shanahan and Claudia Clopath Continual reinforcement learning with complex synapses arXiv preprint arXiv Jeremias Knoblauch Hisham Husain and Tom Diethe Optimal continual learning has perfect memory and np-hard International Conference Machine Learning pages PMLR Tobias Koch Lukas Liebel Friedrich Fraundorfer and Marco Korner Evaluation cnn-based single-image depth estimation methods Proceedings the European Conference Computer Vision ECCV Workshops pages Alex Krizhevsky Vinod Nair and Geoffrey Hinton The CIFARDataset online https://www.cs.toronto.edu/ krizcifarhtml Timothee Lesort Massimo Caccia and Irina Rish Understanding continual learning settings with data distribution drift analysis arXiv preprint arXiv Timothee Lesort Hugo Caselles-Dupre Michael GarciaOrtiz Andrei Stoian and David Filliat Generative models from the perspective continual learning International Joint Conference Neural Networks IJCNN pages IEEE Zhizhong and Derek Hoiem Learning without forgetting IEEE transactions pattern analysis and machine intelligence Xialei Liu Hao Yang Avinash Ravichandran Rahul Bhotika and Stefano Soatto Multi-task incremental learning for object detection Yaoyao Liu Yuting An-An Liu Bernt Schiele and Qianru Sun Mnemonics training Multi-class incremental learning without forgetting Proceedings the IEEECVF Conference Computer Vision and Pattern Recognition pages David Lopez-Paz and MarcAurelio Ranzato Gradient episodic memory for continual learning Advances neural information processing systems pages Andrea Maracani Umberto Michieli Marco Toldo and Pietro Zanuttigh Recall Replay-based continual learning semantic segmentation Proceedings the IEEECVF International Conference Computer Vision ICCV pages October Lars Mescheder Michael Oechsle Michael Niemeyer Sebastian Nowozin and Andreas Geiger Occupancy networks Learning reconstruction function space Proceedings the IEEE Conference Computer Vision and Pattern Recognition pages Umberto Michieli and Pietro Zanuttigh Incremental learning techniques for semantic segmentation Proceedings the IEEECVF International Conference Computer Vision ICCV Workshops Oct Ameya Prabhu Philip Torr and Puneet Dokania Gdumb simple approach that questions our progress continual learning ECCV Charles Hao Kaichun and Leonidas Guibas Pointnet Deep learning point sets for classification and segmentation Proceedings the IEEE conference computer vision and pattern recognition pages Michael Ramamonjisoa and Vincent Lepetit Sharpnet Fast and accurate recovery occluding contours monocular depth estimation Proceedings the IEEECVF International Conference Computer Vision ICCV Workshops Oct Dushyant Rao Francesco Visin Andrei Rusu Razvan Pascanu Yee Whye Teh and Raia Hadsell Continual unsupervised representation learning Advances Neural Information Processing Systems pages Anthony Robins Catastrophic Forgetting Rehearsal and Pseudorehearsal Connection Science Yossi Rubner Carlo Tomasi and Leonidas Guibas The earth movers distance metric for image retrieval International journal computer vision Olga Russakovsky Jia Deng Hao Jonathan Krause Sanjeev Satheesh Sean Zhiheng Huang Andrej Karpathy Aditya Khosla Michael Bernstein Imagenet large scale visual recognition challenge International journal computer vision Daeyun Shin Charless Fowlkes and Derek Hoiem Pixels voxels and views study shape representations for single view object shape prediction Proceedings the IEEE conference computer vision and pattern recognition pages Konstantin Shmelkov Cordelia Schmid and Karteek Alahari Incremental learning object detectors without catastrophic forgetting Proceedings the IEEE International Conference Computer Vision pages Stefan Stojanov Samarth Mishra Ngoc Anh Thai Nikhil Dhanda Ahmad Humayun Chen Linda Smith and James Rehg Incremental object learning from contiguous views Proceedings the IEEE Conference Computer Vision and Pattern Recognition pages Oral Best Paper Finalist Maxim Tatarchenko Stephan Richter Rene Ranftl Zhuwen Vladlen Koltun and Thomas Brox What single-view reconstruction networks learn? Proceedings the IEEE Conference Computer Vision and Pattern Recognition pages Anh Thai Stefan Stojanov Vijay Upadhya and James Rehg reconstruction novel object shapes from single images arXiv preprint arXiv Gido Van Ven and Andreas Tolias Three scenarios for continual learning arXiv preprint arXiv Eli Verwimp Matthias Lange and Tinne Tuytelaars Rehearsal revealed The limits and merits revisiting samples continual learning Proceedings the IEEECVF International Conference Computer Vision ICCV pages October Jianren Wang Xin Wang Yue Shang-Guan and Abhinav Gupta Wanderlust Online continual object detection the real world Proceedings the IEEECVF International Conference Computer Vision ICCV pages October Shuzhe Wang Zakaria Laskar Iaroslav Melekhov Xiaotian and Juho Kannala Continual learning for image-based camera localization Proceedings the IEEECVF International Conference Computer Vision pages Zhou Wang Alan Bovik Hamid Sheikh and Eero Simoncelli Image quality assessment from error visibility structural similarity IEEE transactions image processing Ziyun Wang Volkan Isler and Daniel Lee Surface hof Surface reconstruction from single image using higher order function networks IEEE International Conference Image Processing ICIP pages IEEE Chenshen Luis Herranz Xialei Liu Joost van Weijer Bogdan Raducanu Memory replay gans Learning generate new categories without forgetting Advances Neural Information Processing Systems pages Jiajun Yifan Wang Tianfan Xue Xingyuan Sun Bill Freeman and Josh Tenenbaum Marrnet shape reconstruction via sketches Advances neural information processing systems pages Yue Yinpeng Chen Lijuan Wang Yuancheng Zicheng Liu Yandong Guo and Yun Large scale incremental learning Proceedings the IEEE Conference Computer Vision and Pattern Recognition pages Jianxiong Xiao James Hays Krista Ehinger Aude Oliva and Antonio Torralba Sun database Large-scale scene recognition from abbey zoo IEEE Computer Society Conference Computer Vision and Pattern Recognition pages IEEE and Zhanxing Zhu Reinforced continual learning Advances Neural Information Processing Systems pages Qiangeng Weiyue Wang Duygu Ceylan Radomir Mech and Ulrich Neumann Disn Deep implicit surface network for high-quality single-view reconstruction Zike Yan Yuxin Tian Xuesong Shi Ping Guo Peng Wang and Hongbin Zha Continual neural mapping Learning implicit scene representation from sequential observations Proceedings the IEEECVF International Conference Computer Vision ICCV pages October Bartlomiej Twardowski Xialei Liu Luis Herranz Kai Wang Yongmei Cheng Shangling Jui and Joost van Weijer Semantic drift compensation for class-incremental learning Proceedings the IEEECVF Conference Computer Vision and Pattern Recognition CVPR June Junting Zhang Jie Zhang Shalini Ghosh Dawei Serafettin Tasci Larry Heck Heming Zhang and C-C Jay Kuo Class-incremental learning via deep model consolidation The IEEE Winter Conference Applications Computer Vision pages Xiuming Zhang Zhoutong Zhang Chengkai Zhang Joshua Tenenbaum William Freeman and Jiajun Learning Reconstruct Shapes from Unseen Classes Advances Neural Information Processing Systems NeurIPS This supplementary material document structured follows Sec describe the training data more detail Sec provide details the algorithms used the paper their training implementation details and evaluation metrics Section further explain the repeated exposures setting Datasets ShapeNetCorev Datasets ShapeNetCorev consists categories with CAD models This the current largest shape dataset with category labels Many prior works shape reconstruction utilized subset largest categoriesShapeNet which consists approximately instances Tbl lists the categories and the number samples each category For ShapeNet use the standard trainvaltest split from prior shape reconstruction works sample objectscategory from the test split for evaluation the repeated exposures case For the remaining classes ShapeNetCorev split randomly with proportion for trainvaltest splits the single exposure case all classes ShapeNetCorev randomly sample objectscategory for testing For evaluating novel category generalization ability sample objects from the classes The license ShapeNetCorev specified https://shapenet.org/terms. Rendering render views RGB images ground truth silhouette depth and surface normal maps with resolution for each object Following generate data using Cycles ray-tracing engine Blender with degree-of-freedom varying camera azimuth elevation and tilt For experiments with RGB images inputs render with varying light specular surface reflectance and random backgrounds from SUN Scenes SDF Point Sampling Strategy For shape reconstruction training points are sampled more densely close the surface the mesh Following sample half the training points within distance the surface with distance the range and the range train and evaluate OccNet obtain mesh occupancy values binary masking sdf where the isosurface value CIFARThis standard image dataset consisting categories with training and testing samples for each category Each image resolution our experiment for classification baselines with repeated exposures categories are chosen randomly from categories which denote CIFARName Num samples airplane bench cabinet car chair display lamp loudspeaker rifle sofa table telephone watercraft Total Table Statistics ShapeNet Description Algorithms Single Object Shape Reconstruction Secs Architecture adapt SDFNet and OccNet with ResNetencoder for continual training with and inputs and SDFNet with PointNet encoder for input Specifically the architecture consists encoder initialized with random weights and point module which are multiple blocks fully-connected layers with ReLU activation Conditional Batch Normalization used applying affine transformation the output the point module conditioned the feature vector produced the encoder GDumb For Shape employ SDFNet with ResNetencoder the backbone architecture and follow the training procedure GDumb for classification task Specifically randomly select exemplar set size the training data equally divided for all the seen categories each learning exposure initialize the learning model randomly train from scratch the selected exemplar set each learning exposure GSmart Different from GDumb for shape continuously update the representation each learning exposure Please see Algs for the pseudo code algorithms evaluated Sec the main text Loss function SDFNet uses loss the loss function with high weights for points close the surface Specifically otherwise where the ground truth SDF value and the predicted SDF value https://shapenet.org/terms Algorithm GDumb for Shape Input Batch training procedure SDFNetDtrainDval that returns the trained parameters and the performance the trained model Dval Data RGB image coordinates SDF values pair datasets Dtrain TiD train Dval TiD val Define weighted loss init Exemplar set foreach learning exposure RANDOM INIT SELECT RANDOMC Dtraint acct SDFNet CDvalt end Result acc acc accT Algorithm GSmart Input Batch training procedure SDFNetDtrainDval that returns the trained parameters and the performance the trained model Dval Data RGB image coordinates SDF values pair datasets Dtrain TiD train Dval TiD val Define weighted loss init Exemplar set foreach learning exposure SELECT RANDOMC Dtraint acct SDFNet CDvalt end Result acc acc accT OccNet uses Binary Cross Entropy BCE loss each input point Specifically log log where the ground truth binary value and the predicted probability whether point inside outside the mesh Mesh generation use MISE algorithm that hierarchically extracts the mesh isosurface introduced generate the predicted mesh Instead generating the SDFoccupancy values for all the points uniformly sampled the cube MISE starts from lower resolution and hierarchically determines the voxels that contain the mesh subdivide until the desired resolution reached adapt Algorithm C-SDFNet Input Batch training procedure SDFNetDtrainDval that returns the trained parameters and the performance the trained model Dval Data RGB image coordinates SDF values pair datasets Dtrain TiD train Dval TiD val Define weighted loss foreach learning exposure acct SDFNetDtraint Dvalt end Result acc acc accT MISE work both SDF and occupancy values Metric Following use F-Score our main evaluation metric first sample and points respectively the surface the predicted mesh and ground truth mesh The metric computed the following FS@1 prec@1 rec@1 prec@1 rec@1 where prec@1 the precision which measures the portion points from that lie within threshold the points from the case where the mesh normalized fit unit cube and rec@1 the recall which measures the portion points from that lie within threshold the points from Single-view Sketches Prediction Sec Architecture adapt the sketch estimation from MarrNet for continual training The backbone architecture for MarrNet U-ResNet with the ResNet image encoder initialized with ILSVRCpre-trained weights Loss functions use MSE the loss function for depth and normals prediction Specifically MSEI where and are the ground truth and predicted images respectively Metrics For depth prediction report threshold accuracy percentage such that max y?i y?i where and yi? are the predicted and ground truth depth values pixel and the threshold our evaluation use For normals report cosine distance threshold the main metric first convert the RGB values the normal map into vectors where and are the normal and color vectors respectively Cosine distance threshold accuracy then computed where and are predicted and ground truth normals set Reconstruction Sec Silhouette Prediction use MarrNet the backbone architecture for continual training with BCE loss function report Intersection-over-Union for silhouette prediction the metric Specifically IoUI Image Autoencoding Architecture implement shallow network with conv layers each followed max pooling layer which termed ConvAutoEncoder Each conv layer has channels and the dimension the bottle-neck feature vector The network randomly initialized Loss function train ConvAutoEncoder with MSE loss for each pixel defined where the size the input image and the input channels red green blue Metric use SSIM scaled range the main evaluation metric for the image autoencoding experiment Specifically given two image windows and the same size the original SSIM metric computed SSIMx cxy with the averages and respectively are the variances and the covariance and respectively are constants avoid dividing the denominator Classification Baselines Sec GDumb algorithm that randomly selects exemplars and performs training the exemplar set only each learning exposure the model trained from scratch the exemplar set which each category represented with the same number samples GDumb utilizes the standard cross-entropy loss and classifies using the network outputs used our PyTorch implementation GDumb with ResNet initialized randomly the feature extractor Classifier with Exemplars simple baseline where train standard classifier with cross-entropy loss continually each learning exposure the learning model trained the current training data combined with the randomly selected exemplar set without any further heuristics Similar GDumb use randomly initialized ResNet the feature extractor ImageNet Pretrained the baseline use highlight that the feature space learned single-view shape model from RGB image without ground truth label discriminative For each new class randomly select the exemplar set from the training data test time first extract the feature representation from the ILSVRCpretrained ResNet for each test sample then perform NCM predict the label using the exemplar set Further Explanation for Repeated Exposures Setting the repeated exposure setting each class occurs fixed number times repetitions random order For example the case classes repeated times would first generate learning exposures and then perform random permutation obtain the order seen the learner result classes repeat complex and highlyvariable patterns Note that even though classes repeat each learning exposure still contains only single class small number thereby preserving the domain shift between exposures that makes challenging"
" new type Hybrid Chaos Systems Reza Parvaz Department Mathematics University Mohaghegh Ardabili Ardabil Iran rparvaz@uma.ac.ir Abstract this paper new type chaotic system based sin and logistic systems introduced Also the behavior this new system studied using various tests The results these tests indicate the appropriate behavior for the proposed new system Key words Chaos system Logistic map Hybrid systemIntroduction recent years the use chaotic functions has been considered due its structure These types systems are used image encryption Also due the weaknesses that classical functions have the use combination method improve this group functions considered this article present fourdimensional chaos system that can used create different four-dimensional chaos systems This system can used various algorithms including the use image encryption algorithm should noted that all calculations this article have been done using MATLAB software Hybrid Chaos Systems Structure the Proposed Hybrid System this section more details about the proposed new hybrid chaos systems based Tent Sin and Logistic maps are given The general structure the proposed chaos system has been given Fig The combination parts the proposed system based Tent Sin and Logistic maps are shown Fig The mathematics formulae for each the parts can written follows relations First combination part Second combination part Third combination part Fourth combination part Where and for for can considered Sin Logistic maps for are arbitrary number and are considered arbitrary sufficiently smooth functions the proposed system the best feature the different chaos maps Tent Sin and Logistic maps have been improved using Composition and transfer operator the following the basic properties the hybrid system have been studied the subsections order study hybrid system the following cases have been considered Figure The structure the proposed chaotic system Figure The structure the combination parts the proposed system chaotic system Case cosh cot sin exp tanh sin cos exp log tan exp tan exp sin tan exp sin cot exp cot Case cos exp sin sin log exp cos log cot sin exp sin cot log exp cos log cos exp cos Also the case are considered Tent map and are considered Sin map For case and are considered Tent and Sin maps respectively Chaotic Behavior Analysis this subsection same important tests for the proposed chaos system are discussed One the important values the study the behavior the chaos system Lyapunov exponent Lyapunov characteristic exponentdimensional chaos systems general have values for Lyapunov exponent There are many methods for calculating this value The method based algorithm has been used for obtained Lyaponov exponent Fig for the case More details about this method can found The positive negative values the resulting values are related with the structure chaos system This relation had been studied many papers the relation has been given follows n-dimensional dynamical system have Lyapunov exponents Each represents the divergencevolume The sign the Lyapunov exponents indicates the behavior nearby trajectories negative exponent indicates that neighboring trajectories converge the same trajectory positive exponent indicates that neighboring trajectories diverge Also the following theorem has been given for this value Theorem least one the average Lyapunov exponents positive then the system chaotic the average Lyapunov exponent negative then the orbit periodic and when the average Lyapunov exponent zero bifurcation occurs The results Fig show that all four value Lyapunov exponent the proposed system are positive Then using above studies can say that the proposed system the all neighboring trajectories diverge order compare proposed system the Lyapunov exponent has been compared with Chaotic Laser System Fig observed that the proposed system has better chaos behavior then Chaotic Laser System Another tool for study chaotic behavior bifurcation analysis the Fig the results for the bifurcation analysis the case the proposed system have been shown The chaotic attractors can studied this figure The attractor for given the vertical line that Also the cobweb plot Verhulst diagram for case have been given the Figs using this results observed that for the given values the resulting sequences the proposed system has chaotic behavior Distribution another important factor chaotic system One the reasons for the weakness the statistical attack nonuniform distribution The histogram plots the proposed system for the case are Figure Lyapunov exponent values for Case Chaotic system Figure Bifurcation diagram results for the case https://en.wikipedia.org/wiki/Chaos_(mathematics) https://en.wikipedia.org/wiki/Attractor https://en.wikipedia.org/wiki/Attractor given the Fig Also the distribution patterns the case are shown Fig using these results can seen that the generated sequence the proposed maps have flat distribution Reference Wolf Alan Jack Swift Harry Swinney and John Vastano Determining Lyapunov exponents from time series Physica Nonlinear Phenomena Figure Histogram plots the case for Figure Distribution patterns the case for Sano Masaki and Yasuji Sawada Measurement the Lyapunov spectrum from chaotic time series Physical review letters Dmitrieva Lyudmila Yuri Kuperin Nikolai Smetanin and German Chernykh Method calculating Lyapunov exponents for time series using artificial neural networks committees Days Diffraction IEEE Van Opstall Michael Quantifying Chaos Dynamical Systems with Lyapunov Exponents Furman University Electronic Journal Undergraduate Mathematics Lynch Stephen Dynamical systems with applications using Matlab Springer Natiq Hayder Mohamad Said Nadia Al-Saidi and Adem Kilicman Dynamics and complexity new chaotic laser system Entropy"